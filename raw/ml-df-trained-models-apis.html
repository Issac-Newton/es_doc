<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="keywords" content="hot-spotting, hotspot, hot-spot, hot spot, hotspots, hotspotting">
<title>Machine learning trained model APIs | Elasticsearch Guide | Elastic</title>
<meta class="elastic" name="content" content="Machine learning trained model APIs | Elasticsearch Guide">

<link rel="home" href="index.html" title="Elasticsearch Guide"/>
<link rel="up" href="rest-apis.html" title="REST APIs"/>
<link rel="prev" href="ml-df-analytics-apis.html" title="Machine learning data frame analytics APIs"/>
<link rel="next" href="migration-api.html" title="Migration APIs"/>
<meta class="elastic" name="product_version" content=""/>
<meta class="elastic" name="product_name" content=""/>
<meta class="elastic" name="website_area" content="documentation"/>
<meta name="DC.type" content="Learn/Docs/"/>
<meta name="DC.subject" content=""/>
<meta name="DC.identifier" content=""/>
</head>
<body>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="/guide/">Elastic Docs</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="index.html">Elasticsearch Guide</a></span>
<span class="chevron-right">›</span><span class="breadcrumb-link"><a href="rest-apis.html">REST APIs</a></span>
</div>
<div class="navheader">
<span class="prev">
<a href="ml-df-analytics-apis.html">« Machine learning data frame analytics APIs</a>
</span>
<span class="next">
<a href="migration-api.html">Migration APIs »</a>
</span>
</div>
<div class="chapter xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="ml-df-trained-models-apis"></a>Machine learning trained model APIs<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/ml-trained-models-apis.asciidoc">edit</a></h2>
</div></div></div>
<p>You can use the following APIs to perform model management operations:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="ml-df-trained-models-apis.html#clear-trained-model-deployment-cache" title="Clear trained model deployment cache API">Clear trained model deployment cache</a>
</li>
<li class="listitem">
<a class="xref" href="ml-df-trained-models-apis.html#put-trained-models" title="Create trained models API">Create trained models</a>
</li>
<li class="listitem">
<a class="xref" href="ml-df-trained-models-apis.html#put-trained-model-definition-part" title="Create trained model definition part API">Create part of a trained model</a>
</li>
<li class="listitem">
<a class="xref" href="ml-df-trained-models-apis.html#put-trained-model-vocabulary" title="Create trained model vocabulary API">Create trained model vocabulary</a>
</li>
<li class="listitem">
<a class="xref" href="ml-df-trained-models-apis.html#put-trained-models-aliases" title="Create or update trained model aliases API">Create or update trained model aliases</a>
</li>
<li class="listitem">
<a class="xref" href="ml-df-trained-models-apis.html#delete-trained-models" title="Delete trained models API">Delete trained models</a>
</li>
<li class="listitem">
<a class="xref" href="ml-df-trained-models-apis.html#delete-trained-models-aliases" title="Delete trained model aliases API">Delete trained model aliases</a>
</li>
<li class="listitem">
<a class="xref" href="ml-df-trained-models-apis.html#get-trained-models" title="Get trained models API">Get trained models</a>
</li>
<li class="listitem">
<a class="xref" href="ml-df-trained-models-apis.html#get-trained-models-stats" title="Get trained models statistics API">Get trained models stats</a>
</li>
<li class="listitem">
<a class="xref" href="ml-df-trained-models-apis.html#infer-trained-model" title="Infer trained model API">Infer trained model</a>
</li>
<li class="listitem">
<a class="xref" href="ml-df-trained-models-apis.html#start-trained-model-deployment" title="Start trained model deployment API">Start trained model deployment</a>
</li>
<li class="listitem">
<a class="xref" href="ml-df-trained-models-apis.html#stop-trained-model-deployment" title="Stop trained model deployment API">Stop trained model deployment</a>
</li>
<li class="listitem">
<a class="xref" href="ml-df-trained-models-apis.html#update-trained-model-deployment" title="Update trained model deployment API">Update trained model deployment</a>
</li>
</ul>
</div>
<p>You can deploy a trained model to make predictions in an ingest pipeline or in
an aggregation. Refer to the following documentation to learn more:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="search-aggregations-pipeline.html#search-aggregations-pipeline-inference-bucket-aggregation" title="Inference bucket aggregation">Inference bucket aggregation</a>
</li>
<li class="listitem">
<a class="xref" href="processors.html#inference-processor" title="Inference processor">Inference processor</a>
</li>
</ul>
</div>
<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="clear-trained-model-deployment-cache"></a>Clear trained model deployment cache API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/clear-trained-model-deployment-cache.asciidoc">edit</a></h2>
</div></div></div>

<p>Clears the inference cache on all nodes where the deployment is assigned.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="clear-trained-model-deployment-cache-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/clear-trained-model-deployment-cache.asciidoc">edit</a></h3>
</div></div></div>
<p><code class="literal">POST _ml/trained_models/&lt;deployment_id&gt;/deployment/cache/_clear</code></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="clear-trained-model-deployment-cache-prereq"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/clear-trained-model-deployment-cache.asciidoc">edit</a></h3>
</div></div></div>
<p>Requires the <code class="literal">manage_ml</code> cluster privilege. This privilege is included in the
<code class="literal">machine_learning_admin</code> built-in role.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="clear-trained-model-deployment-cache-desc"></a>Description<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/clear-trained-model-deployment-cache.asciidoc">edit</a></h3>
</div></div></div>
<p>A trained model deployment may have an inference cache enabled. As requests are
handled by each allocated node, their responses may be cached on that individual
node. Calling this API clears the caches without restarting the deployment.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="clear-trained-model-deployment-cache-path-params"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/clear-trained-model-deployment-cache.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">deployment_id</code>
</span>
</dt>
<dd>
(Required, string)
A unique identifier for the deployment of the model.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="clear-trained-model-deployment-cache-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/clear-trained-model-deployment-cache.asciidoc">edit</a></h3>
</div></div></div>
<p>The following example clears the cache for the new deployment for the
<code class="literal">elastic__distilbert-base-uncased-finetuned-conll03-english</code> trained model:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ml/trained_models/elastic__distilbert-base-uncased-finetuned-conll03-english/deployment/cache/_clear</pre>
</div>
<div class="console_widget" data-snippet="snippets/2678.console"></div>
<p>The API returns the following results:</p>
<div class="pre_wrapper lang-console-result">
<pre class="programlisting prettyprint lang-console-result">{
   "cleared": true
}</pre>
</div>
</div>

</div>

<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="put-trained-models-aliases"></a>Create or update trained model aliases API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models-aliases.asciidoc">edit</a></h2>
</div></div></div>

<p>Creates or updates a trained model alias.</p>
<p>A trained model alias is a logical name used to reference a single trained model.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-aliases-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models-aliases.asciidoc">edit</a></h3>
</div></div></div>
<p><code class="literal">PUT _ml/trained_models/&lt;model_id&gt;/model_aliases/&lt;model_alias&gt;</code></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-aliases-prereq"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models-aliases.asciidoc">edit</a></h3>
</div></div></div>
<p>Requires the <code class="literal">manage_ml</code> cluster privilege. This privilege is included in the
<code class="literal">machine_learning_admin</code> built-in role.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-aliases-desc"></a>Description<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models-aliases.asciidoc">edit</a></h3>
</div></div></div>
<p>You can use aliases instead of trained model identifiers to make it easier to
reference your models. For example, you can use aliases in inference aggregations
and processors.</p>
<p>An alias must be unique and refer to only a single trained model. However,
you can have multiple aliases for each trained model.</p>
<p>API Restrictions:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
You are not allowed to update an alias such that it references a different
trained model ID and the model uses a different type of data frame analytics. For example,
this situation occurs if you have a trained model for
regression analysis and a trained model for classification analysis; you cannot reassign an
alias from one type of trained model to another.
</li>
<li class="listitem">
You cannot update an alias from a <code class="literal">pytorch</code> model and a data frame analytics model.
</li>
<li class="listitem">
You cannot update the alias from a deployed <code class="literal">pytorch</code> model to one
not currently deployed.
</li>
</ul>
</div>
<p>If you use this API to update an alias and there are very few input fields in
common between the old and new trained models for the model alias, the API
returns a warning.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-aliases-path-params"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models-aliases.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">model_alias</code>
</span>
</dt>
<dd>
(Required, string)
The alias to create or update. This value cannot end in numbers.
</dd>
<dt>
<span class="term">
<code class="literal">model_id</code>
</span>
</dt>
<dd>
(Required, string)
The identifier for the trained model that the alias refers to.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-aliases-query-params"></a>Query parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models-aliases.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">reassign</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies whether the alias gets reassigned to the specified trained model if it
is already assigned to a different model. If the alias is already assigned and
this parameter is <code class="literal">false</code>, the API returns an error. Defaults to <code class="literal">false</code>.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-aliases-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models-aliases.asciidoc">edit</a></h3>
</div></div></div>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="ml-put-trained-models-aliases-example-new-alias"></a>Create a trained model alias<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models-aliases.asciidoc">edit</a></h4>
</div></div></div>
<p>The following example shows how to create an alias (<code class="literal">flight_delay_model</code>) for a
trained model (<code class="literal">flight-delay-prediction-1574775339910</code>):</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT _ml/trained_models/flight-delay-prediction-1574775339910/model_aliases/flight_delay_model</pre>
</div>
<div class="console_widget" data-snippet="snippets/2679.console"></div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="ml-put-trained-models-aliases-example-put-alias"></a>Update a trained model alias<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models-aliases.asciidoc">edit</a></h4>
</div></div></div>
<p>The following example shows how to reassign an alias (<code class="literal">flight_delay_model</code>) to a
different trained model (<code class="literal">flight-delay-prediction-1580004349800</code>):</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT _ml/trained_models/flight-delay-prediction-1580004349800/model_aliases/flight_delay_model?reassign=true</pre>
</div>
<div class="console_widget" data-snippet="snippets/2680.console"></div>
</div>

</div>

</div>

<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="put-trained-model-definition-part"></a>Create trained model definition part API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-model-definition-part.asciidoc">edit</a></h2>
</div></div></div>

<p>Creates part of a trained model definition.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-model-definition-part-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-model-definition-part.asciidoc">edit</a></h3>
</div></div></div>
<p><code class="literal">PUT _ml/trained_models/&lt;model_id&gt;/definition/&lt;part_num&gt;</code></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-model-definition-part-prereq"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-model-definition-part.asciidoc">edit</a></h3>
</div></div></div>
<p>Requires the <code class="literal">manage_ml</code> cluster privilege. This privilege is included in the
<code class="literal">machine_learning_admin</code> built-in role.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-model-definition-part-path-params"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-model-definition-part.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;model_id&gt;</code>
</span>
</dt>
<dd>
(Required, string)
The unique identifier of the trained model.
</dd>
<dt>
<span class="term">
<code class="literal">&lt;part&gt;</code>
</span>
</dt>
<dd>
(Required, number)
The definition part number. When the definition is loaded for inference
the definition parts will be streamed in order of their <code class="literal">part_num</code>.
The first part must be <code class="literal">0</code> and the final part must be <code class="literal">total_parts - 1</code>.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-model-definition-part-request-body"></a>Request body<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-model-definition-part.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">definition</code>
</span>
</dt>
<dd>
(Required, string)
The definition part for the model. Must be a base64 encoded string.
</dd>
<dt>
<span class="term">
<code class="literal">total_definition_length</code>
</span>
</dt>
<dd>
(Required, number)
The total uncompressed definition length in bytes. Not base64 encoded.
</dd>
<dt>
<span class="term">
<code class="literal">total_parts</code>
</span>
</dt>
<dd>
(Required, number)
The total number of parts that will be uploaded. Must be greater than 0.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-model-definition-part-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-model-definition-part.asciidoc">edit</a></h3>
</div></div></div>
<p>The following example creates a model definition part for a previously
stored model configuration. The definition part is stored in the index
that is configured by the <code class="literal">location.index.name</code>.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>The value of the <code class="literal">definition</code> object is elided from the example
as it is a very large base64 encoded string.</p>
</div>
</div>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT _ml/trained_models/elastic__distilbert-base-uncased-finetuned-conll03-english/definition/0
{
    "definition": "...",
    "total_definition_length": 265632637,
    "total_parts": 64
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/2681.console"></div>
<p>The API returns the following results:</p>
<div class="pre_wrapper lang-console-result">
<pre class="programlisting prettyprint lang-console-result">{
    "acknowledged": true
}</pre>
</div>
</div>

</div>

<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="put-trained-models"></a>Create trained models API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h2>
</div></div></div>

<p>Creates a trained model.</p>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p>Models created in version 7.8.0 are not backwards compatible
         with older node versions. If in a mixed cluster environment,
         all nodes must be at least 7.8.0 to use a model stored by
         a 7.8.0 node.</p>
</div>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<p><code class="literal">PUT _ml/trained_models/&lt;model_id&gt;</code></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-prereq"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<p>Requires the <code class="literal">manage_ml</code> cluster privilege. This privilege is included in the
<code class="literal">machine_learning_admin</code> built-in role.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-desc"></a>Description<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<p>The create trained model API enables you to supply a trained model that is not
created by data frame analytics.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-path-params"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;model_id&gt;</code>
</span>
</dt>
<dd>
(Required, string)
The unique identifier of the trained model.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-query-params"></a>Query parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">defer_definition_decompression</code>
</span>
</dt>
<dd>
(Optional, boolean)
If set to <code class="literal">true</code> and a <code class="literal">compressed_definition</code> is provided, the request defers
definition decompression and skips relevant validations.
This deferral is useful for systems or users that know a good byte size estimate for their
model and know that their model is valid and likely won&#8217;t fail during inference.
</dd>
</dl>
</div>
</div>

<div class="section child_attributes">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-request-body"></a>Request body<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">compressed_definition</code>
</span>
</dt>
<dd>
(Required, string)
The compressed (GZipped and Base64 encoded) inference definition of the model.
If <code class="literal">compressed_definition</code> is specified, then <code class="literal">definition</code> cannot be specified.
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">definition</code>
</span>
</dt>
<dd>
<p>
(Required, object)
The inference definition for the model. If <code class="literal">definition</code> is specified, then
<code class="literal">compressed_definition</code> cannot be specified.
</p>
<details open>
<summary class="title">Properties of <code class="literal">definition</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">preprocessors</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Collection of preprocessors. See <a class="xref" href="ml-df-trained-models-apis.html#ml-put-trained-models-preprocessor-example" title="Preprocessor examples">Preprocessor examples</a>.
</p>
<details open>
<summary class="title">Properties of <code class="literal">preprocessors</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">frequency_encoding</code>
</span>
</dt>
<dd>
<p>
(Required, object)
Defines a frequency encoding for a field.
</p>
<details open>
<summary class="title">Properties of <code class="literal">frequency_encoding</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">feature_name</code>
</span>
</dt>
<dd>
(Required, string)
The name of the resulting feature.
</dd>
<dt>
<span class="term">
<code class="literal">field</code>
</span>
</dt>
<dd>
(Required, string)
The field name to encode.
</dd>
<dt>
<span class="term">
<code class="literal">frequency_map</code>
</span>
</dt>
<dd>
(Required, object map of string:double)
Object that maps the field value to the frequency encoded value.
</dd>
<dt>
<span class="term">
<code class="literal">custom</code>
</span>
</dt>
<dd>
(Optional, Boolean)
Boolean value indicating if the analytics job created the preprocessor
or if a user provided it. This adjusts the feature importance calculation.
When <code class="literal">true</code>, the feature importance calculation returns importance for the
processed feature. When <code class="literal">false</code>, the total importance of the original field
is returned. Default is <code class="literal">false</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">one_hot_encoding</code>
</span>
</dt>
<dd>
<p>
(Required, object)
Defines a one hot encoding map for a field.
</p>
<details open>
<summary class="title">Properties of <code class="literal">one_hot_encoding</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">field</code>
</span>
</dt>
<dd>
(Required, string)
The field name to encode.
</dd>
<dt>
<span class="term">
<code class="literal">hot_map</code>
</span>
</dt>
<dd>
(Required, object map of strings)
String map of "field_value: one_hot_column_name".
</dd>
<dt>
<span class="term">
<code class="literal">custom</code>
</span>
</dt>
<dd>
(Optional, Boolean)
Boolean value indicating if the analytics job created the preprocessor
or if a user provided it. This adjusts the feature importance calculation.
When <code class="literal">true</code>, the feature importance calculation returns importance for the
processed feature. When <code class="literal">false</code>, the total importance of the original field
is returned. Default is <code class="literal">false</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">target_mean_encoding</code>
</span>
</dt>
<dd>
<p>
(Required, object)
Defines a target mean encoding for a field.
</p>
<details open>
<summary class="title">Properties of <code class="literal">target_mean_encoding</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">default_value</code>
</span>
</dt>
<dd>
(Required, double)
The feature value if the field value is not in the <code class="literal">target_map</code>.
</dd>
<dt>
<span class="term">
<code class="literal">feature_name</code>
</span>
</dt>
<dd>
(Required, string)
The name of the resulting feature.
</dd>
<dt>
<span class="term">
<code class="literal">field</code>
</span>
</dt>
<dd>
(Required, string)
The field name to encode.
</dd>
<dt>
<span class="term">
<code class="literal">target_map</code>
</span>
</dt>
<dd>
<p>
(Required, object map of string:double)
Object that maps the field value to the target mean value.
</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">custom</code>
</span>
</dt>
<dd>
(Optional, Boolean)
Boolean value indicating if the analytics job created the preprocessor
or if a user provided it. This adjusts the feature importance calculation.
When <code class="literal">true</code>, the feature importance calculation returns importance for the
processed feature. When <code class="literal">false</code>, the total importance of the original field
is returned. Default is <code class="literal">false</code>.
</dd>
</dl>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">trained_model</code>
</span>
</dt>
<dd>
<p>
(Required, object)
The definition of the trained model.
</p>
<details open>
<summary class="title">Properties of <code class="literal">trained_model</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">tree</code>
</span>
</dt>
<dd>
<p>
(Required, object)
The definition for a binary decision tree.
</p>
<details open>
<summary class="title">Properties of <code class="literal">tree</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Optional, string) An array of classification labels (used for
<code class="literal">classification</code>).
</dd>
<dt>
<span class="term">
<code class="literal">feature_names</code>
</span>
</dt>
<dd>
(Required, string)
Features expected by the tree, in their expected order.
</dd>
<dt>
<span class="term">
<code class="literal">target_type</code>
</span>
</dt>
<dd>
(Required, string)
String indicating the model target type; <code class="literal">regression</code> or <code class="literal">classification</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tree_structure</code>
</span>
</dt>
<dd>
(Required, object)
An array of <code class="literal">tree_node</code> objects. The nodes must be in ordinal order by their
<code class="literal">tree_node.node_index</code> value.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">tree_node</code>
</span>
</dt>
<dd>
<p>
(Required, object)
The definition of a node in a tree.
</p>
<p>There are two major types of nodes: leaf nodes and not-leaf nodes.</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Leaf nodes only need <code class="literal">node_index</code> and <code class="literal">leaf_value</code> defined.
</li>
<li class="listitem">
All other nodes need <code class="literal">split_feature</code>, <code class="literal">left_child</code>, <code class="literal">right_child</code>,
<code class="literal">threshold</code>, <code class="literal">decision_type</code>, and <code class="literal">default_left</code> defined.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of <code class="literal">tree_node</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">decision_type</code>
</span>
</dt>
<dd>
(Optional, string)
Indicates the positive value (in other words, when to choose the left node)
decision type. Supported <code class="literal">lt</code>, <code class="literal">lte</code>, <code class="literal">gt</code>, <code class="literal">gte</code>. Defaults to <code class="literal">lte</code>.
</dd>
<dt>
<span class="term">
<code class="literal">default_left</code>
</span>
</dt>
<dd>
(Optional, Boolean)
Indicates whether to default to the left when the feature is missing. Defaults
to <code class="literal">true</code>.
</dd>
<dt>
<span class="term">
<code class="literal">leaf_value</code>
</span>
</dt>
<dd>
(Optional, double)
The leaf value of the of the node, if the value is a leaf (in other words, no
children).
</dd>
<dt>
<span class="term">
<code class="literal">left_child</code>
</span>
</dt>
<dd>
(Optional, integer)
The index of the left child.
</dd>
<dt>
<span class="term">
<code class="literal">node_index</code>
</span>
</dt>
<dd>
(Integer)
The index of the current node.
</dd>
<dt>
<span class="term">
<code class="literal">right_child</code>
</span>
</dt>
<dd>
(Optional, integer)
The index of the right child.
</dd>
<dt>
<span class="term">
<code class="literal">split_feature</code>
</span>
</dt>
<dd>
(Optional, integer)
The index of the feature value in the feature array.
</dd>
<dt>
<span class="term">
<code class="literal">split_gain</code>
</span>
</dt>
<dd>
(Optional, double) The information gain from the split.
</dd>
<dt>
<span class="term">
<code class="literal">threshold</code>
</span>
</dt>
<dd>
(Optional, double)
The decision threshold with which to compare the feature value.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">ensemble</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The definition for an ensemble model. See <a class="xref" href="ml-df-trained-models-apis.html#ml-put-trained-models-model-example" title="Model examples">Model examples</a>.
</p>
<details open>
<summary class="title">Properties of <code class="literal">ensemble</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">aggregate_output</code>
</span>
</dt>
<dd>
<p>
(Required, object)
An aggregated output object that defines how to aggregate the outputs of the
<code class="literal">trained_models</code>. Supported objects are <code class="literal">weighted_mode</code>, <code class="literal">weighted_sum</code>, and
<code class="literal">logistic_regression</code>. See <a class="xref" href="ml-df-trained-models-apis.html#ml-put-trained-models-aggregated-output-example" title="Aggregated output example">Aggregated output example</a>.
</p>
<details open>
<summary class="title">Properties of <code class="literal">aggregate_output</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">logistic_regression</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
This <code class="literal">aggregated_output</code> type works with binary classification (classification
for values [0, 1]). It multiplies the outputs (in the case of the <code class="literal">ensemble</code>
model, the inference model values) by the supplied <code class="literal">weights</code>. The resulting
vector is summed and passed to a
<a href="https://en.wikipedia.org/wiki/Sigmoid_function" class="ulink" target="_top"><code class="literal">sigmoid</code> function</a>. The result
of the <code class="literal">sigmoid</code> function is considered the probability of class 1 (<code class="literal">P_1</code>),
consequently, the probability of class 0 is <code class="literal">1 - P_1</code>. The class with the
highest probability (either 0 or 1) is then returned. For more information about
logistic regression, see
<a href="https://en.wikipedia.org/wiki/Logistic_regression" class="ulink" target="_top">this wiki article</a>.
</p>
<details open>
<summary class="title">Properties of <code class="literal">logistic_regression</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">weights</code>
</span>
</dt>
<dd>
(Required, double)
The weights to multiply by the input values (the inference values of the trained
models).
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">weighted_sum</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
This <code class="literal">aggregated_output</code> type works with regression. The weighted sum of the
input values.
</p>
<details open>
<summary class="title">Properties of <code class="literal">weighted_sum</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">weights</code>
</span>
</dt>
<dd>
(Required, double)
The weights to multiply by the input values (the inference values of the trained
models).
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">weighted_mode</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
This <code class="literal">aggregated_output</code> type works with regression or classification. It takes
a weighted vote of the input values. The most common input value (taking the
weights into account) is returned.
</p>
<details open>
<summary class="title">Properties of <code class="literal">weighted_mode</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">weights</code>
</span>
</dt>
<dd>
(Required, double)
The weights to multiply by the input values (the inference values of the trained
models).
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">exponent</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
This <code class="literal">aggregated_output</code> type works with regression. It takes a weighted sum of
the input values and passes the result to an exponent function
(<code class="literal">e^x</code> where <code class="literal">x</code> is the sum of the weighted values).
</p>
<details open>
<summary class="title">Properties of <code class="literal">exponent</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">weights</code>
</span>
</dt>
<dd>
(Required, double)
The weights to multiply by the input values (the inference values of the trained
models).
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Optional, string)
An array of classification labels.
</dd>
<dt>
<span class="term">
<code class="literal">feature_names</code>
</span>
</dt>
<dd>
(Optional, string)
Features expected by the ensemble, in their expected order.
</dd>
<dt>
<span class="term">
<code class="literal">target_type</code>
</span>
</dt>
<dd>
(Required, string)
String indicating the model target type; <code class="literal">regression</code> or <code class="literal">classification.</code>
</dd>
<dt>
<span class="term">
<code class="literal">trained_models</code>
</span>
</dt>
<dd>
(Required, object)
An array of <code class="literal">trained_model</code> objects. Supported trained models are <code class="literal">tree</code> and
<code class="literal">ensemble</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">description</code>
</span>
</dt>
<dd>
(Optional, string)
A human-readable description of the inference trained model.
</dd>
<dt>
<span class="term">
<code class="literal">estimated_heap_memory_usage_bytes</code>
</span>
</dt>
<dd>
(Optional, integer) <span class="Admonishment Admonishment--change">
[<span class="Admonishment-version u-mono u-strikethrough">7.16.0</span>]
<span class="Admonishment-detail">
Deprecated in 7.16.0. Replaced by <code class="literal">model_size_bytes</code>
</span>
</span>
</dd>
<dt>
<span class="term">
<code class="literal">estimated_operations</code>
</span>
</dt>
<dd>
(Optional, integer)
The estimated number of operations to use the trained model during inference.
This property is supported only if <code class="literal">defer_definition_decompression</code> is <code class="literal">true</code> or
the model definition is not supplied.
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">inference_config</code>
</span>
</dt>
<dd>
<p>
(Required, object)
The default configuration for inference. This can be: <code class="literal">regression</code>,
<code class="literal">classification</code>, <code class="literal">fill_mask</code>, <code class="literal">ner</code>, <code class="literal">question_answering</code>,
<code class="literal">text_classification</code>, <code class="literal">text_embedding</code> or <code class="literal">zero_shot_classification</code>.
If <code class="literal">regression</code> or <code class="literal">classification</code>, it must match the <code class="literal">target_type</code> of the
underlying <code class="literal">definition.trained_model</code>. If <code class="literal">fill_mask</code>, <code class="literal">ner</code>,
<code class="literal">question_answering</code>, <code class="literal">text_classification</code>, or <code class="literal">text_embedding</code>; the
<code class="literal">model_type</code> must be <code class="literal">pytorch</code>.
</p>
<details open>
<summary class="title">Properties of <code class="literal">inference_config</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Classification configuration for inference.
</p>
<details open>
<summary class="title">Properties of classification inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">num_top_classes</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the number of top class predictions to return. Defaults to 0.
</dd>
<dt>
<span class="term">
<code class="literal">num_top_feature_importance_values</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of
<a href="https://www.elastic.co/guide/en/machine-learning/8.9/ml-feature-importance.html" class="ulink" target="_top">feature importance</a> values per document. Defaults
to 0 which means no feature importance calculation occurs.
</dd>
<dt>
<span class="term">
<code class="literal">prediction_field_type</code>
</span>
</dt>
<dd>
(Optional, string)
Specifies the type of the predicted field to write.
Valid values are: <code class="literal">string</code>, <code class="literal">number</code>, <code class="literal">boolean</code>. When <code class="literal">boolean</code> is provided
<code class="literal">1.0</code> is transformed to <code class="literal">true</code> and <code class="literal">0.0</code> to <code class="literal">false</code>.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">top_classes_results_field</code>
</span>
</dt>
<dd>
(Optional, string)
Specifies the field to which the top classes are written. Defaults to
<code class="literal">top_classes</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">fill_mask</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configuration for a fill_mask natural language processing (NLP) task. The
fill_mask task works with models optimized for a fill mask action. For example,
for BERT models, the following text may be provided: "The capital of France is
[MASK].". The response indicates the value most likely to replace <code class="literal">[MASK]</code>. In
this instance, the most probable token is <code class="literal">paris</code>.
</p>
<details open>
<summary class="title">Properties of fill_mask inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">num_top_classes</code>
</span>
</dt>
<dd>
(Optional, integer)
Number of top predicted tokens to return for replacing the mask token. Defaults to <code class="literal">0</code>.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
(Optional, boolean)
Tokenize with special tokens if <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">ner</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configures a named entity recognition (NER) task. NER is a special case of token
classification. Each token in the sequence is classified according to the
provided classification labels. Currently, the NER task requires the
<code class="literal">classification_labels</code> Inside-Outside-Beginning (IOB) formatted labels. Only
person, organization, location, and miscellaneous are supported.
</p>
<details open>
<summary class="title">Properties of ner inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Optional, string)
An array of classification labels. NER only supports Inside-Outside-Beginning
labels (IOB) and only persons, organizations, locations, and miscellaneous.
Example: ["O", "B-PER", "I-PER", "B-ORG", "I-ORG", "B-LOC", "I-LOC", "B-MISC",
"I-MISC"]
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
(Optional, boolean)
Tokenize with special tokens if <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">pass_through</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configures a <code class="literal">pass_through</code> task. This task is useful for debugging as no
post-processing is done to the inference output and the raw pooling layer
results are returned to the caller.
</p>
<details open>
<summary class="title">Properties of pass_through inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
(Optional, boolean)
Tokenize with special tokens if <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">question_answering</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configures a question answering natural language processing (NLP) task. Question
answering is useful for extracting answers for certain questions from a large
corpus of text.
</p>
<details open>
<summary class="title">Properties of question_answering inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_answer_length</code>
</span>
</dt>
<dd>
(Optional, integer)
The maximum amount of words in the answer. Defaults to <code class="literal">15</code>.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<p>Recommended to set <code class="literal">max_sentence_length</code> to <code class="literal">386</code> with <code class="literal">128</code> of <code class="literal">span</code> and set
<code class="literal">truncate</code> to <code class="literal">none</code>.</p>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
(Optional, boolean)
Tokenize with special tokens if <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">regression</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Regression configuration for inference.
</p>
<details open>
<summary class="title">Properties of regression inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">num_top_feature_importance_values</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of
<a href="https://www.elastic.co/guide/en/machine-learning/8.9/ml-feature-importance.html" class="ulink" target="_top">feature importance</a> values per document.
By default, it is zero and no feature importance calculation occurs.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">text_classification</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
A text classification task. Text classification classifies a provided text
sequence into previously known target classes. A specific example of this is
sentiment analysis, which returns the likely target classes indicating text
sentiment, such as "sad", "happy", or "angry".
</p>
<details open>
<summary class="title">Properties of text_classification inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Optional, string) An array of classification labels.
</dd>
<dt>
<span class="term">
<code class="literal">num_top_classes</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the number of top class predictions to return. Defaults to all classes (-1).
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
(Optional, boolean)
Tokenize with special tokens if <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">text_embedding</code>
</span>
</dt>
<dd>
<p>
(Object, optional)
Text embedding takes an input sequence and transforms it into a vector of
numbers. These embeddings capture not simply tokens, but semantic meanings and
context. These embeddings can be used in a <a class="xref" href="mapping-types.html#dense-vector" title="Dense vector field type">dense vector</a> field
for powerful insights.
</p>
<details open>
<summary class="title">Properties of text_embedding inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">embedding_size</code>
</span>
</dt>
<dd>
(Optional, integer)
The number of dimensions in the embedding vector produced by the model.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
(Optional, boolean)
Tokenize with special tokens if <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">text_similarity</code>
</span>
</dt>
<dd>
(Object, optional)
Text similarity takes an input sequence and compares it with another input sequence. This is commonly referred to
as cross-encoding. This task is useful for ranking document text when comparing it to another provided text input.
</dd>
</dl>
</div>
<details open>
<summary class="title">Properties of text_similarity inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span_score_combination_function</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Identifies how to combine the resulting similarity score when a provided text passage is longer than <code class="literal">max_sequence_length</code> and must be
automatically separated for multiple calls. This only is applicable when <code class="literal">truncate</code> is <code class="literal">none</code> and <code class="literal">span</code> is a non-negative
number. The default value is <code class="literal">max</code>. Available options are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">max</code>: The maximum score from all the spans is returned.
</li>
<li class="listitem">
<code class="literal">mean</code>: The mean score over all the spans is returned.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
(Optional, boolean)
Tokenize with special tokens if <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">zero_shot_classification</code>
</span>
</dt>
<dd>
<p>
(Object, optional)
Configures a zero-shot classification task. Zero-shot classification allows for
text classification to occur without pre-determined labels. At inference time,
it is possible to adjust the labels to classify. This makes this type of model
and task exceptionally flexible.
</p>
<p>If consistently classifying the same labels, it may be better to use a
fine-tuned text classification model.</p>
<details open>
<summary class="title">Properties of zero_shot_classification inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Required, array)
The classification labels used during the zero-shot classification. Classification
labels must not be empty or null and only set at model creation. They must be all three
of ["entailment", "neutral", "contradiction"].
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>This is NOT the same as <code class="literal">labels</code> which are the values that zero-shot is attempting to
      classify.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">hypothesis_template</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
This is the template used when tokenizing the sequences for classification.
</p>
<p>The labels replace the <code class="literal">{}</code> value in the text. The default value is:
<code class="literal">This example is {}.</code></p>
</dd>
<dt>
<span class="term">
<code class="literal">labels</code>
</span>
</dt>
<dd>
(Optional, array)
The labels to classify. Can be set at creation for default labels, and
then updated during inference.
</dd>
<dt>
<span class="term">
<code class="literal">multi_label</code>
</span>
</dt>
<dd>
(Optional, boolean)
Indicates if more than one <code class="literal">true</code> label is possible given the input.
This is useful when labeling text that could pertain to more than one of the
input labels. Defaults to <code class="literal">false</code>.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
(Optional, boolean)
Tokenize with special tokens if <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">input</code>
</span>
</dt>
<dd>
<p>
(Required, object)
The input field names for the model definition.
</p>
<details open>
<summary class="title">Properties of <code class="literal">input</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">field_names</code>
</span>
</dt>
<dd>
(Required, string)
An array of input field names for the model.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">location</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The model definition location. If the <code class="literal">definition</code> or <code class="literal">compressed_definition</code>
are not specified, the <code class="literal">location</code> is required.
</p>
<details open>
<summary class="title">Properties of <code class="literal">location</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, object)
Indicates that the model definition is stored in an index. This object must be
empty as the index for storing model definitions is configured automatically.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">metadata</code>
</span>
</dt>
<dd>
(Optional, object)
An object map that contains metadata about the model.
</dd>
<dt>
<span class="term">
<code class="literal">model_size_bytes</code>
</span>
</dt>
<dd>
(Optional, integer)
The estimated memory usage in bytes to keep the trained model in memory. This
property is supported only if <code class="literal">defer_definition_decompression</code> is <code class="literal">true</code> or the
model definition is not supplied.
</dd>
<dt>
<span class="term">
<code class="literal">model_type</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
The created model type. By default the model type is <code class="literal">tree_ensemble</code>.
Appropriate types are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">tree_ensemble</code>: The model definition is an ensemble model of decision trees.
</li>
<li class="listitem">
<code class="literal">lang_ident</code>: A special type reserved for language identification models.
</li>
<li class="listitem">
<code class="literal">pytorch</code>: The stored definition is a PyTorch (specifically a TorchScript) model. Currently only
NLP models are supported. For more information, refer to <a href="https://www.elastic.co/guide/en/machine-learning/8.9/ml-nlp.html" class="ulink" target="_top">Natural language processing</a>.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">tags</code>
</span>
</dt>
<dd>
(Optional, string)
An array of tags to organize the model.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-models-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="ml-put-trained-models-preprocessor-example"></a>Preprocessor examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h4>
</div></div></div>
<p>The example below shows a <code class="literal">frequency_encoding</code> preprocessor object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">{
   "frequency_encoding":{
      "field":"FlightDelayType",
      "feature_name":"FlightDelayType_frequency",
      "frequency_map":{
         "Carrier Delay":0.6007414737092798,
         "NAS Delay":0.6007414737092798,
         "Weather Delay":0.024573576178086153,
         "Security Delay":0.02476631010889467,
         "No Delay":0.6007414737092798,
         "Late Aircraft Delay":0.6007414737092798
      }
   }
}</pre>
</div>
<p>The next example shows a <code class="literal">one_hot_encoding</code> preprocessor object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">{
   "one_hot_encoding":{
      "field":"FlightDelayType",
      "hot_map":{
         "Carrier Delay":"FlightDelayType_Carrier Delay",
         "NAS Delay":"FlightDelayType_NAS Delay",
         "No Delay":"FlightDelayType_No Delay",
         "Late Aircraft Delay":"FlightDelayType_Late Aircraft Delay"
      }
   }
}</pre>
</div>
<p>This example shows a <code class="literal">target_mean_encoding</code> preprocessor object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">{
   "target_mean_encoding":{
      "field":"FlightDelayType",
      "feature_name":"FlightDelayType_targetmean",
      "target_map":{
         "Carrier Delay":39.97465788139886,
         "NAS Delay":39.97465788139886,
         "Security Delay":203.171206225681,
         "Weather Delay":187.64705882352948,
         "No Delay":39.97465788139886,
         "Late Aircraft Delay":39.97465788139886
      },
      "default_value":158.17995752420433
   }
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="ml-put-trained-models-model-example"></a>Model examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h4>
</div></div></div>
<p>The first example shows a <code class="literal">trained_model</code> object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">{
   "tree":{
      "feature_names":[
         "DistanceKilometers",
         "FlightTimeMin",
         "FlightDelayType_NAS Delay",
         "Origin_targetmean",
         "DestRegion_targetmean",
         "DestCityName_targetmean",
         "OriginAirportID_targetmean",
         "OriginCityName_frequency",
         "DistanceMiles",
         "FlightDelayType_Late Aircraft Delay"
      ],
      "tree_structure":[
         {
            "decision_type":"lt",
            "threshold":9069.33437193022,
            "split_feature":0,
            "split_gain":4112.094574306927,
            "node_index":0,
            "default_left":true,
            "left_child":1,
            "right_child":2
         },
         ...
         {
            "node_index":9,
            "leaf_value":-27.68987349695448
         },
         ...
      ],
      "target_type":"regression"
   }
}</pre>
</div>
<p>The following example shows an <code class="literal">ensemble</code> model object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">"ensemble":{
   "feature_names":[
      ...
   ],
   "trained_models":[
      {
         "tree":{
            "feature_names":[],
            "tree_structure":[
               {
                  "decision_type":"lte",
                  "node_index":0,
                  "leaf_value":47.64069875778043,
                  "default_left":false
               }
            ],
            "target_type":"regression"
         }
      },
      ...
   ],
   "aggregate_output":{
      "weighted_sum":{
         "weights":[
            ...
         ]
      }
   },
   "target_type":"regression"
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="ml-put-trained-models-aggregated-output-example"></a>Aggregated output example<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h4>
</div></div></div>
<p>Example of a <code class="literal">logistic_regression</code> object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">"aggregate_output" : {
  "logistic_regression" : {
    "weights" : [2.0, 1.0, .5, -1.0, 5.0, 1.0, 1.0]
  }
}</pre>
</div>
<p>Example of a <code class="literal">weighted_sum</code> object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">"aggregate_output" : {
  "weighted_sum" : {
    "weights" : [1.0, -1.0, .5, 1.0, 5.0]
  }
}</pre>
</div>
<p>Example of a <code class="literal">weighted_mode</code> object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">"aggregate_output" : {
  "weighted_mode" : {
    "weights" : [1.0, 1.0, 1.0, 1.0, 1.0]
  }
}</pre>
</div>
<p>Example of an <code class="literal">exponent</code> object:</p>
<div class="pre_wrapper lang-js">
<pre class="programlisting prettyprint lang-js">"aggregate_output" : {
  "exponent" : {
    "weights" : [1.0, 1.0, 1.0, 1.0, 1.0]
  }
}</pre>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="ml-put-trained-models-json-schema"></a>Trained models JSON schema<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-models.asciidoc">edit</a></h4>
</div></div></div>
<p>For the full JSON schema of trained models,
<a href="https://github.com/elastic/ml-json-schemas" class="ulink" target="_top">click here</a>.</p>
</div>

</div>

</div>

<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="put-trained-model-vocabulary"></a>Create trained model vocabulary API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-model-vocabulary.asciidoc">edit</a></h2>
</div></div></div>

<p>Creates a trained model vocabulary.
This is supported only for natural language processing (NLP) models.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-model-vocabulary-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-model-vocabulary.asciidoc">edit</a></h3>
</div></div></div>
<p><code class="literal">PUT _ml/trained_models/&lt;model_id&gt;/vocabulary/</code></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-model-vocabulary-prereq"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-model-vocabulary.asciidoc">edit</a></h3>
</div></div></div>
<p>Requires the <code class="literal">manage_ml</code> cluster privilege. This privilege is included in the
<code class="literal">machine_learning_admin</code> built-in role.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-model-vocabulary-desc"></a>Description<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-model-vocabulary.asciidoc">edit</a></h3>
</div></div></div>
<p>The vocabulary is stored in the index as described in
<code class="literal">inference_config.*.vocabulary</code> of the trained model definition.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-model-vocabulary-path-params"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-model-vocabulary.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;model_id&gt;</code>
</span>
</dt>
<dd>
(Required, string)
The unique identifier of the trained model.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-model-vocabulary-request-body"></a>Request body<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-model-vocabulary.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">vocabulary</code>
</span>
</dt>
<dd>
(array)
The model vocabulary. Must not be empty.
</dd>
<dt>
<span class="term">
<code class="literal">merges</code>
</span>
</dt>
<dd>
(Optional, array)
The model merges used in byte-pair encoding. The merges must be sub-token pairs, space delimited, and in order of
preference. Example: ["f o", "fo o"]. Must be provided for RoBERTa and BART style models.
</dd>
<dt>
<span class="term">
<code class="literal">scores</code>
</span>
</dt>
<dd>
(Optional, array)
Vocabulary value scores used by sentence-piece tokenization. Must have the same length as <code class="literal">vocabulary</code>.
Required for unigram sentence-piece tokenized models like XLMRoberta and T5.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-put-trained-model-vocabulary-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/put-trained-model-vocabulary.asciidoc">edit</a></h3>
</div></div></div>
<p>The following example shows how to create a model vocabulary for a
previously stored trained model configuration.</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">PUT _ml/trained_models/elastic__distilbert-base-uncased-finetuned-conll03-english/vocabulary
{
  "vocabulary": [
    "[PAD]",
    "[unused0]",
    ...
  ]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/2682.console"></div>
<p>The API returns the following results:</p>
<div class="pre_wrapper lang-console-result">
<pre class="programlisting prettyprint lang-console-result">{
    "acknowledged": true
}</pre>
</div>
</div>

</div>

<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="delete-trained-models-aliases"></a>Delete trained model aliases API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/delete-trained-models-aliases.asciidoc">edit</a></h2>
</div></div></div>

<p>Deletes a trained model alias.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-delete-trained-models-aliases-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/delete-trained-models-aliases.asciidoc">edit</a></h3>
</div></div></div>
<p><code class="literal">DELETE _ml/trained_models/&lt;model_id&gt;/model_aliases/&lt;model_alias&gt;</code></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-delete-trained-models-aliases-prereq"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/delete-trained-models-aliases.asciidoc">edit</a></h3>
</div></div></div>
<p>Requires the <code class="literal">manage_ml</code> cluster privilege. This privilege is included in the
<code class="literal">machine_learning_admin</code> built-in role.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-delete-trained-models-aliases-desc"></a>Description<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/delete-trained-models-aliases.asciidoc">edit</a></h3>
</div></div></div>
<p>This API deletes an existing model alias that refers to a trained model.</p>
<p>If the model alias is missing or refers to a model other than the one identified
by the <code class="literal">model_id</code>, this API returns an error.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-delete-trained-models-aliases-path-params"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/delete-trained-models-aliases.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">model_alias</code>
</span>
</dt>
<dd>
(Required, string)
The model alias to delete.
</dd>
<dt>
<span class="term">
<code class="literal">model_id</code>
</span>
</dt>
<dd>
(Required, string)
The trained model ID to which the model alias refers.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-delete-trained-models-aliases-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/delete-trained-models-aliases.asciidoc">edit</a></h3>
</div></div></div>
<p>The following example shows how to delete a model alias (<code class="literal">flight_delay_model</code>)
for a trained model ID (<code class="literal">flight-delay-prediction-1574775339910</code>):</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">DELETE _ml/trained_models/flight-delay-prediction-1574775339910/model_aliases/flight_delay_model</pre>
</div>
<div class="console_widget" data-snippet="snippets/2683.console"></div>
</div>

</div>

<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="delete-trained-models"></a>Delete trained models API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/delete-trained-models.asciidoc">edit</a></h2>
</div></div></div>

<p>Deletes an existing trained inference model.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-delete-trained-models-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/delete-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<p><code class="literal">DELETE _ml/trained_models/&lt;model_id&gt;</code></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-delete-trained-models-prereq"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/delete-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<p>Requires the <code class="literal">manage_ml</code> cluster privilege. This privilege is included in the
<code class="literal">machine_learning_admin</code> built-in role.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-delete-trained-models-path-params"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/delete-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;model_id&gt;</code>
</span>
</dt>
<dd>
(Optional, string)
The unique identifier of the trained model.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-delete-trained-models-query-parms"></a>Query parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/delete-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">force</code>
</span>
</dt>
<dd>
(Optional, Boolean) Use to forcefully delete a trained model that is referenced
by ingest pipelines or has a started deployment.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-delete-trained-models-response-codes"></a>Response codes<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/delete-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">409</code>
</span>
</dt>
<dd>
The code indicates that the trained model is referenced by an ingest pipeline
and cannot be deleted.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-delete-trained-models-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/delete-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<p>The following example deletes the <code class="literal">regression-job-one-1574775307356</code> trained
model:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">DELETE _ml/trained_models/regression-job-one-1574775307356</pre>
</div>
<div class="console_widget" data-snippet="snippets/2684.console"></div>
<p>The API returns the following result:</p>
<div class="pre_wrapper lang-console-result">
<pre class="programlisting prettyprint lang-console-result">{
  "acknowledged" : true
}</pre>
</div>
</div>

</div>

<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="get-trained-models"></a>Get trained models API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models.asciidoc">edit</a></h2>
</div></div></div>

<p>Retrieves configuration information for a trained model.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<p><code class="literal">GET _ml/trained_models/</code><br></p>
<p><code class="literal">GET _ml/trained_models/&lt;model_id&gt;</code><br></p>
<p><code class="literal">GET _ml/trained_models/_all</code><br></p>
<p><code class="literal">GET _ml/trained_models/&lt;model_id1&gt;,&lt;model_id2&gt;</code><br></p>
<p><code class="literal">GET _ml/trained_models/&lt;model_id_pattern*&gt;</code></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-prereq"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<p>Requires the <code class="literal">monitor_ml</code> cluster privilege. This privilege is included in the
<code class="literal">machine_learning_user</code> built-in role.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-path-params"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;model_id&gt;</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
The unique identifier of the trained model or a model alias.
</p>
<p>You can get information for multiple trained models in a single API request by
using a comma-separated list of model IDs or a wildcard expression.</p>
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-query-params"></a>Query parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">allow_no_match</code>
</span>
</dt>
<dd>
<p>
(Optional, Boolean)
Specifies what to do when the request:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Contains wildcard expressions and there are no models that match.
</li>
<li class="listitem">
Contains the <code class="literal">_all</code> string or no identifiers and there are no matches.
</li>
<li class="listitem">
Contains wildcard expressions and there are only partial matches.
</li>
</ul>
</div>
<p>The default value is <code class="literal">true</code>, which returns an empty array when there are no
matches and the subset of results when there are partial matches. If this
parameter is <code class="literal">false</code>, the request returns a <code class="literal">404</code> status code when there are no
matches or only partial matches.</p>
</dd>
<dt>
<span class="term">
<code class="literal">decompress_definition</code>
</span>
</dt>
<dd>
(Optional, Boolean)
Specifies whether the included model definition should be returned as a JSON map
(<code class="literal">true</code>) or in a custom compressed format (<code class="literal">false</code>). Defaults to <code class="literal">true</code>.
</dd>
<dt>
<span class="term">
<code class="literal">exclude_generated</code>
</span>
</dt>
<dd>
(Optional, Boolean)
Indicates if certain fields should be removed from the configuration on
retrieval. This allows the configuration to be in an acceptable format to be retrieved
and then added to another cluster. Default is false.
</dd>
<dt>
<span class="term">
<code class="literal">from</code>
</span>
</dt>
<dd>
(Optional, integer)
Skips the specified number of models. The default value is <code class="literal">0</code>.
</dd>
<dt>
<span class="term">
<code class="literal">include</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
A comma delimited string of optional fields to include in the response body. The
default value is empty, indicating no optional fields are included. Valid
options are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">definition</code>: Includes the model definition.
</li>
<li class="listitem">
<code class="literal">feature_importance_baseline</code>: Includes the baseline for feature importance values.
</li>
<li class="listitem">
<code class="literal">hyperparameters</code>: Includes the information about hyperparameters used to
train the model. This information consists of the value, the absolute and
relative importance of the hyperparameter as well as an indicator of whether
it was specified by the user or tuned during hyperparameter optimization.
</li>
<li class="listitem">
<code class="literal">total_feature_importance</code>: Includes the total feature importance for the training
data set.
</li>
<li class="listitem">
<code class="literal">definition_status</code>: Includes the field <code class="literal">fully_defined</code> indicating if the
full model definition is present.
The baseline and total feature importance values are returned in the <code class="literal">metadata</code> field
in the response body.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">size</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of models to obtain. The default value
is <code class="literal">100</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tags</code>
</span>
</dt>
<dd>
(Optional, string)
A comma delimited string of tags. A trained model can have many tags, or none.
When supplied, only trained models that contain all the supplied tags are
returned.
</dd>
</dl>
</div>
</div>

<div class="section child_attributes">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-results"></a>Response body<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">trained_model_configs</code>
</span>
</dt>
<dd>
<p>
(array)
An array of trained model resources, which are sorted by the <code class="literal">model_id</code> value in
ascending order.
</p>
<details open>
<summary class="title">Properties of trained model resources</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">created_by</code>
</span>
</dt>
<dd>
(string)
The creator of the trained model.
</dd>
<dt>
<span class="term">
<code class="literal">create_time</code>
</span>
</dt>
<dd>
(<a class="xref" href="api-conventions.html#time-units" title="Time units">time units</a>)
The time when the trained model was created.
</dd>
<dt>
<span class="term">
<code class="literal">default_field_map</code>
</span>
</dt>
<dd>
<p>
(object)
A string object that contains the default field map to use when inferring
against the model. For example, data frame analytics may train the model on a specific
multi-field <code class="literal">foo.keyword</code>. The analytics job would then supply a default field
map entry for <code class="literal">"foo" : "foo.keyword"</code>.
</p>
<p>Any field map described in the inference configuration takes precedence.</p>
</dd>
<dt>
<span class="term">
<code class="literal">description</code>
</span>
</dt>
<dd>
(string)
The free-text description of the trained model.
</dd>
<dt>
<span class="term">
<code class="literal">model_size_bytes</code>
</span>
</dt>
<dd>
(integer)
The estimated model size in bytes to keep the trained model in memory.
</dd>
<dt>
<span class="term">
<code class="literal">estimated_operations</code>
</span>
</dt>
<dd>
(integer)
The estimated number of operations to use the trained model.
</dd>
<dt>
<span class="term">
<code class="literal">inference_config</code>
</span>
</dt>
<dd>
<p>
(object)
The default configuration for inference. This can be either a <code class="literal">regression</code>
or <code class="literal">classification</code> configuration. It must match the <code class="literal">target_type</code> of the
underlying <code class="literal">definition.trained_model</code>.
</p>
<details open>
<summary class="title">Properties of <code class="literal">inference_config</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification</code>
</span>
</dt>
<dd>
<p>
(object)
Classification configuration for inference.
</p>
<details open>
<summary class="title">Properties of classification inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">num_top_classes</code>
</span>
</dt>
<dd>
(integer)
Specifies the number of top class predictions to return. Defaults to 0.
</dd>
<dt>
<span class="term">
<code class="literal">num_top_feature_importance_values</code>
</span>
</dt>
<dd>
(integer)
Specifies the maximum number of
<a href="https://www.elastic.co/guide/en/machine-learning/8.9/ml-feature-importance.html" class="ulink" target="_top">feature importance</a> values per document. Defaults
to 0 which means no feature importance calculation occurs.
</dd>
<dt>
<span class="term">
<code class="literal">prediction_field_type</code>
</span>
</dt>
<dd>
(string)
Specifies the type of the predicted field to write.
Valid values are: <code class="literal">string</code>, <code class="literal">number</code>, <code class="literal">boolean</code>. When <code class="literal">boolean</code> is provided
<code class="literal">1.0</code> is transformed to <code class="literal">true</code> and <code class="literal">0.0</code> to <code class="literal">false</code>.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">top_classes_results_field</code>
</span>
</dt>
<dd>
(string)
Specifies the field to which the top classes are written. Defaults to
<code class="literal">top_classes</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">fill_mask</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configuration for a fill_mask natural language processing (NLP) task. The
fill_mask task works with models optimized for a fill mask action. For example,
for BERT models, the following text may be provided: "The capital of France is
[MASK].". The response indicates the value most likely to replace <code class="literal">[MASK]</code>. In
this instance, the most probable token is <code class="literal">paris</code>.
</p>
<details open>
<summary class="title">Properties of fill_mask inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
(Optional, boolean)
Tokenize with special tokens if <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">vocabulary</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The configuration for retrieving the vocabulary of the model. The vocabulary is
then used at inference time. This information is usually provided automatically
by storing vocabulary in a known, internally managed index.
</p>
<details open>
<summary class="title">Properties of vocabulary</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, string)
The index where the vocabulary is stored.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">ner</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configures a named entity recognition (NER) task. NER is a special case of token
classification. Each token in the sequence is classified according to the
provided classification labels. Currently, the NER task requires the
<code class="literal">classification_labels</code> Inside-Outside-Beginning (IOB) formatted labels. Only
person, organization, location, and miscellaneous are supported.
</p>
<details open>
<summary class="title">Properties of ner inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Optional, string)
An array of classification labels. NER supports only
Inside-Outside-Beginning labels (IOB) and only persons, organizations, locations,
and miscellaneous. For example:
<code class="literal">["O", "B-PER", "I-PER", "B-ORG", "I-ORG", "B-LOC", "I-LOC", "B-MISC", "I-MISC"]</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
(Optional, boolean)
Tokenize with special tokens if <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">vocabulary</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The configuration for retrieving the vocabulary of the model. The vocabulary is
then used at inference time. This information is usually provided automatically
by storing vocabulary in a known, internally managed index.
</p>
<details open>
<summary class="title">Properties of vocabulary</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, string)
The index where the vocabulary is stored
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">pass_through</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configures a <code class="literal">pass_through</code> task. This task is useful for debugging as no
post-processing is done to the inference output and the raw pooling layer
results are returned to the caller.
</p>
<details open>
<summary class="title">Properties of pass_through inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
(Optional, boolean)
Tokenize with special tokens if <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">vocabulary</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The configuration for retrieving the vocabulary of the model. The vocabulary is
then used at inference time. This information is usually provided automatically
by storing vocabulary in a known, internally managed index.
</p>
<details open>
<summary class="title">Properties of vocabulary</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, string)
The index where the vocabulary is stored.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">regression</code>
</span>
</dt>
<dd>
<p>
(object)
Regression configuration for inference.
</p>
<details open>
<summary class="title">Properties of regression inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">num_top_feature_importance_values</code>
</span>
</dt>
<dd>
(integer)
Specifies the maximum number of
<a href="https://www.elastic.co/guide/en/machine-learning/8.9/ml-feature-importance.html" class="ulink" target="_top">feature importance</a> values per document.
By default, it is zero and no feature importance calculation occurs.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">text_classification</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
A text classification task. Text classification classifies a provided text
sequence into previously known target classes. A specific example of this is
sentiment analysis, which returns the likely target classes indicating text
sentiment, such as "sad", "happy", or "angry".
</p>
<details open>
<summary class="title">Properties of text_classification inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Optional, string)
An array of classification labels.
</dd>
<dt>
<span class="term">
<code class="literal">num_top_classes</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the number of top class predictions to return. Defaults to all classes (-1).
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
(Optional, boolean)
Tokenize with special tokens if <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">vocabulary</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The configuration for retrieving the vocabulary of the model. The vocabulary is
then used at inference time. This information is usually provided automatically
by storing vocabulary in a known, internally managed index.
</p>
<details open>
<summary class="title">Properties of vocabulary</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, string)
The index where the vocabulary is stored.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">text_embedding</code>
</span>
</dt>
<dd>
<p>
(Object, optional)
Text embedding takes an input sequence and transforms it into a vector of
numbers. These embeddings capture not simply tokens, but semantic meanings and
context. These embeddings can be used in a <a class="xref" href="mapping-types.html#dense-vector" title="Dense vector field type">dense vector</a> field
for powerful insights.
</p>
<details open>
<summary class="title">Properties of text_embedding inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">embedding_size</code>
</span>
</dt>
<dd>
(Optional, integer)
The number of dimensions in the embedding vector produced by the model.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
(Optional, boolean)
Tokenize with special tokens if <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">vocabulary</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The configuration for retrieving the vocabulary of the model. The vocabulary is
then used at inference time. This information is usually provided automatically
by storing vocabulary in a known, internally managed index.
</p>
<details open>
<summary class="title">Properties of vocabulary</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, string)
The index where the vocabulary is stored.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">text_similarity</code>
</span>
</dt>
<dd>
<p>
(Object, optional)
Text similarity takes an input sequence and compares it with another input sequence. This is commonly referred to
as cross-encoding. This task is useful for ranking document text when comparing it to another provided text input.
</p>
<details open>
<summary class="title">Properties of text_similarity inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span_score_combination_function</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Identifies how to combine the resulting similarity score when a provided text passage is longer than <code class="literal">max_sequence_length</code> and must be
automatically separated for multiple calls. This only is applicable when <code class="literal">truncate</code> is <code class="literal">none</code> and <code class="literal">span</code> is a non-negative
number. The default value is <code class="literal">max</code>. Available options are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">max</code>: The maximum score from all the spans is returned.
</li>
<li class="listitem">
<code class="literal">mean</code>: The mean score over all the spans is returned.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
(Optional, boolean)
Tokenize with special tokens if <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">vocabulary</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The configuration for retrieving the vocabulary of the model. The vocabulary is
then used at inference time. This information is usually provided automatically
by storing vocabulary in a known, internally managed index.
</p>
<details open>
<summary class="title">Properties of vocabulary</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, string)
The index where the vocabulary is stored.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">zero_shot_classification</code>
</span>
</dt>
<dd>
<p>
(Object, optional)
Configures a zero-shot classification task. Zero-shot classification allows for
text classification to occur without pre-determined labels. At inference time,
it is possible to adjust the labels to classify. This makes this type of model
and task exceptionally flexible.
</p>
<p>If consistently classifying the same labels, it may be better to use a
fine-tuned text classification model.</p>
<details open>
<summary class="title">Properties of zero_shot_classification inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Required, array)
The classification labels used during the zero-shot classification. Classification
labels must not be empty or null and only set at model creation. They must be all three
of ["entailment", "neutral", "contradiction"].
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>This is NOT the same as <code class="literal">labels</code> which are the values that zero-shot is attempting to
      classify.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">hypothesis_template</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
This is the template used when tokenizing the sequences for classification.
</p>
<p>The labels replace the <code class="literal">{}</code> value in the text. The default value is:
<code class="literal">This example is {}.</code></p>
</dd>
<dt>
<span class="term">
<code class="literal">labels</code>
</span>
</dt>
<dd>
(Optional, array)
The labels to classify. Can be set at creation for default labels, and
then updated during inference.
</dd>
<dt>
<span class="term">
<code class="literal">multi_label</code>
</span>
</dt>
<dd>
(Optional, boolean)
Indicates if more than one <code class="literal">true</code> label is possible given the input.
This is useful when labeling text that could pertain to more than one of the
input labels. Defaults to <code class="literal">false</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">add_prefix_space</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization should prefix a space to the tokenized input to the model.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">&lt;s&gt;</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">&lt;/s&gt;</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">do_lower_case</code>
</span>
</dt>
<dd>
(Optional, boolean)
Specifies if the tokenization lower case the text sequence when building the
tokens.
</dd>
<dt>
<span class="term">
<code class="literal">max_sequence_length</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of tokens allowed to be output by the tokenizer.
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
(Optional, boolean)
Tokenize with special tokens if <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">vocabulary</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The configuration for retrieving the vocabulary of the model. The vocabulary is
then used at inference time. This information is usually provided automatically
by storing vocabulary in a known, internally managed index.
</p>
<details open>
<summary class="title">Properties of vocabulary</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, string)
The index where the vocabulary is stored.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">input</code>
</span>
</dt>
<dd>
<p>
(object)
The input field names for the model definition.
</p>
<details open>
<summary class="title">Properties of <code class="literal">input</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">field_names</code>
</span>
</dt>
<dd>
(string)
An array of input field names for the model.
</dd>
</dl>
</div>
</div>
</details>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">fully_defined</code>
</span>
</dt>
<dd>
(boolean)
True if the full model definition is present.
This field is only present if <code class="literal">include=definition_status</code> was specified in the request.
</dd>
</dl>
</div>
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">location</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The model definition location. Must be provided if the <code class="literal">definition</code> or <code class="literal">compressed_definition</code> are not
provided.
</p>
<details open>
<summary class="title">Properties of <code class="literal">location</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">index</code>
</span>
</dt>
<dd>
(Required, object)
Indicates that the model definition is stored in an index. It is required to be empty as
the index for storing model definitions is configured automatically.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">license_level</code>
</span>
</dt>
<dd>
(string)
The license level of the trained model.
</dd>
<dt>
<span class="term">
<code class="literal">metadata</code>
</span>
</dt>
<dd>
<p>
(object)
An object containing metadata about the trained model. For example, models
created by data frame analytics contain <code class="literal">analysis_config</code> and <code class="literal">input</code> objects.
</p>
<details open>
<summary class="title">Properties of metadata</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">feature_importance_baseline</code>
</span>
</dt>
<dd>
(object)
An object that contains the baseline for feature importance values. For regression analysis,
it is a single value. For classification analysis, there is a value for each class.
</dd>
<dt>
<span class="term">
<code class="literal">hyperparameters</code>
</span>
</dt>
<dd>
<p>
(array)
List of the available hyperparameters optimized during the
<code class="literal">fine_parameter_tuning</code> phase as well as specified by the user.
</p>
<details open>
<summary class="title">Properties of hyperparameters</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">absolute_importance</code>
</span>
</dt>
<dd>
(double)
A positive number showing how much the parameter influences the variation of the
<a href="https://www.elastic.co/guide/en/machine-learning/8.9/dfa-regression-lossfunction.html" class="ulink" target="_top">loss function</a>. For
hyperparameters with values that are not specified by the user but tuned during
hyperparameter optimization.
</dd>
<dt>
<span class="term">
<code class="literal">max_trees</code>
</span>
</dt>
<dd>
(integer)
The maximum number of decision trees in the forest. The maximum value is 2000.
By default, this value is calculated during hyperparameter optimization.
</dd>
<dt>
<span class="term">
<code class="literal">name</code>
</span>
</dt>
<dd>
(string)
Name of the hyperparameter.
</dd>
<dt>
<span class="term">
<code class="literal">relative_importance</code>
</span>
</dt>
<dd>
(double)
A number between 0 and 1 showing the proportion of influence on the variation of
the loss function among all tuned hyperparameters. For hyperparameters with
values that are not specified by the user but tuned during hyperparameter
optimization.
</dd>
<dt>
<span class="term">
<code class="literal">supplied</code>
</span>
</dt>
<dd>
(Boolean)
Indicates if the hyperparameter is specified by the user (<code class="literal">true</code>) or optimized
(<code class="literal">false</code>).
</dd>
<dt>
<span class="term">
<code class="literal">value</code>
</span>
</dt>
<dd>
(double)
The value of the hyperparameter, either optimized or specified by the user.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">total_feature_importance</code>
</span>
</dt>
<dd>
<p>
(array)
An array of the total feature importance for each feature used from
the training data set. This array of objects is returned if data frame analytics trained
the model and the request includes <code class="literal">total_feature_importance</code> in the <code class="literal">include</code>
request parameter.
</p>
<details open>
<summary class="title">Properties of total feature importance</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">feature_name</code>
</span>
</dt>
<dd>
(string)
The feature for which this importance was calculated.
</dd>
<dt>
<span class="term">
<code class="literal">importance</code>
</span>
</dt>
<dd>
<p>
(object)
A collection of feature importance statistics related to the training data set for this particular feature.
</p>
<details open>
<summary class="title">Properties of feature importance</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">mean_magnitude</code>
</span>
</dt>
<dd>
(double)
The average magnitude of this feature across all the training data.
This value is the average of the absolute values of the importance
for this feature.
</dd>
<dt>
<span class="term">
<code class="literal">max</code>
</span>
</dt>
<dd>
(integer)
The maximum importance value across all the training data for this
feature.
</dd>
<dt>
<span class="term">
<code class="literal">min</code>
</span>
</dt>
<dd>
(integer)
The minimum importance value across all the training data for this
feature.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">classes</code>
</span>
</dt>
<dd>
<p>
(array)
If the trained model is a classification model, feature importance statistics are gathered
per target class value.
</p>
<details open>
<summary class="title">Properties of class feature importance</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">class_name</code>
</span>
</dt>
<dd>
(string)
The target class value. Could be a string, boolean, or number.
</dd>
<dt>
<span class="term">
<code class="literal">importance</code>
</span>
</dt>
<dd>
<p>
(object)
A collection of feature importance statistics related to the training data set for this particular feature.
</p>
<details open>
<summary class="title">Properties of feature importance</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">mean_magnitude</code>
</span>
</dt>
<dd>
(double)
The average magnitude of this feature across all the training data.
This value is the average of the absolute values of the importance
for this feature.
</dd>
<dt>
<span class="term">
<code class="literal">max</code>
</span>
</dt>
<dd>
(int)
The maximum importance value across all the training data for this
feature.
</dd>
<dt>
<span class="term">
<code class="literal">min</code>
</span>
</dt>
<dd>
(int)
The minimum importance value across all the training data for this
feature.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">model_id</code>
</span>
</dt>
<dd>
(string)
Identifier for the trained model.
</dd>
<dt>
<span class="term">
<code class="literal">model_type</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
The created model type. By default the model type is <code class="literal">tree_ensemble</code>.
Appropriate types are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">tree_ensemble</code>: The model definition is an ensemble model of decision trees.
</li>
<li class="listitem">
<code class="literal">lang_ident</code>: A special type reserved for language identification models.
</li>
<li class="listitem">
<code class="literal">pytorch</code>: The stored definition is a PyTorch (specifically a TorchScript) model. Currently only
NLP models are supported.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">tags</code>
</span>
</dt>
<dd>
(string)
A comma delimited string of tags. A trained model can have many tags, or none.
</dd>
<dt>
<span class="term">
<code class="literal">version</code>
</span>
</dt>
<dd>
(string)
The Elasticsearch version number in which the trained model was created.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-response-codes"></a>Response codes<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">400</code>
</span>
</dt>
<dd>
If <code class="literal">include_model_definition</code> is <code class="literal">true</code>, this code indicates that more than
one models match the ID pattern.
</dd>
<dt>
<span class="term">
<code class="literal">404</code> (Missing resources)
</span>
</dt>
<dd>
If <code class="literal">allow_no_match</code> is <code class="literal">false</code>, this code indicates that there are no
resources that match the request or only partial matches for the request.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models.asciidoc">edit</a></h3>
</div></div></div>
<p>The following example gets configuration information for all the trained models:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">GET _ml/trained_models/</pre>
</div>
<div class="console_widget" data-snippet="snippets/2685.console"></div>
</div>

</div>

<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="get-trained-models-stats"></a>Get trained models statistics API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models-stats.asciidoc">edit</a></h2>
</div></div></div>

<p>Retrieves usage information for trained models.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-stats-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models-stats.asciidoc">edit</a></h3>
</div></div></div>
<p><code class="literal">GET _ml/trained_models/_stats</code><br></p>
<p><code class="literal">GET _ml/trained_models/_all/_stats</code><br></p>
<p><code class="literal">GET _ml/trained_models/&lt;model_id_or_deployment_id&gt;/_stats</code><br></p>
<p><code class="literal">GET _ml/trained_models/&lt;model_id_or_deployment_id&gt;,&lt;model_id_2_or_deployment_id_2&gt;/_stats</code><br></p>
<p><code class="literal">GET _ml/trained_models/&lt;model_id_pattern*_or_deployment_id_pattern*&gt;,&lt;model_id_2_or_deployment_id_2&gt;/_stats</code></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-stats-prereq"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models-stats.asciidoc">edit</a></h3>
</div></div></div>
<p>Requires the <code class="literal">monitor_ml</code> cluster privilege. This privilege is included in the
<code class="literal">machine_learning_user</code> built-in role.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-stats-desc"></a>Description<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models-stats.asciidoc">edit</a></h3>
</div></div></div>
<p>You can get usage information for multiple trained models or trained model
deployments in a single API request by using a comma-separated list of model
IDs, deployment IDs, or a wildcard expression.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-stats-path-params"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models-stats.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;model_id_or_deployment_id&gt;</code>
</span>
</dt>
<dd>
(Optional, string)
The unique identifier of the model or the deployment. If a model has multiple
deployments, and the ID of one of the deployments matches the model ID, then the
model ID takes precedence; the results are returned for all deployments of the
model.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-stats-query-params"></a>Query parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models-stats.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">allow_no_match</code>
</span>
</dt>
<dd>
<p>
(Optional, Boolean)
Specifies what to do when the request:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Contains wildcard expressions and there are no models that match.
</li>
<li class="listitem">
Contains the <code class="literal">_all</code> string or no identifiers and there are no matches.
</li>
<li class="listitem">
Contains wildcard expressions and there are only partial matches.
</li>
</ul>
</div>
<p>The default value is <code class="literal">true</code>, which returns an empty array when there are no
matches and the subset of results when there are partial matches. If this
parameter is <code class="literal">false</code>, the request returns a <code class="literal">404</code> status code when there are no
matches or only partial matches.</p>
</dd>
<dt>
<span class="term">
<code class="literal">from</code>
</span>
</dt>
<dd>
(Optional, integer)
Skips the specified number of models. The default value is <code class="literal">0</code>.
</dd>
<dt>
<span class="term">
<code class="literal">size</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of models to obtain. The default value
is <code class="literal">100</code>.
</dd>
</dl>
</div>
</div>

<div class="section child_attributes">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-stats-results"></a>Response body<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models-stats.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">count</code>
</span>
</dt>
<dd>
(integer)
The total number of trained model statistics that matched the requested ID
patterns. Could be higher than the number of items in the <code class="literal">trained_model_stats</code>
array as the size of the array is restricted by the supplied <code class="literal">size</code> parameter.
</dd>
<dt>
<span class="term">
<code class="literal">trained_model_stats</code>
</span>
</dt>
<dd>
<p>
(array)
An array of trained model statistics, which are sorted by the <code class="literal">model_id</code> value
in ascending order.
</p>
<details open>
<summary class="title">Properties of trained model stats</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">deployment_stats</code>
</span>
</dt>
<dd>
<p>
(list)
A collection of deployment stats if one of the provided <code class="literal">model_id</code> values
is deployed
</p>
<details open>
<summary class="title">Properties of deployment stats</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">allocation_status</code>
</span>
</dt>
<dd>
<p>
(object)
The detailed allocation status given the deployment configuration.
</p>
<details open>
<summary class="title">Properties of allocation stats</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">allocation_count</code>
</span>
</dt>
<dd>
(integer)
The current number of nodes where the model is allocated.
</dd>
<dt>
<span class="term">
<code class="literal">cache_size</code>
</span>
</dt>
<dd>
(<a class="xref" href="api-conventions.html#byte-units" title="Byte size units">byte value</a>)
The inference cache size (in memory outside the JVM heap) per node for the model.
</dd>
<dt>
<span class="term">
<code class="literal">state</code>
</span>
</dt>
<dd>
<p>
(string)
The detailed allocation state related to the nodes.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">starting</code>: Allocations are being attempted but no node currently has the model allocated.
</li>
<li class="listitem">
<code class="literal">started</code>: At least one node has the model allocated.
</li>
<li class="listitem">
<code class="literal">fully_allocated</code>: The deployment is fully allocated and satisfies the <code class="literal">target_allocation_count</code>.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">target_allocation_count</code>
</span>
</dt>
<dd>
(integer)
The desired number of nodes for model allocation.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">deployment_id</code>
</span>
</dt>
<dd>
A unique identifier for the deployment of the model.
</dd>
<dt>
<span class="term">
<code class="literal">error_count</code>
</span>
</dt>
<dd>
(integer)
The sum of <code class="literal">error_count</code> for all nodes in the deployment.
</dd>
<dt>
<span class="term">
<code class="literal">inference_count</code>
</span>
</dt>
<dd>
(integer)
The sum of <code class="literal">inference_count</code> for all nodes in the deployment.
</dd>
<dt>
<span class="term">
<code class="literal">model_id</code>
</span>
</dt>
<dd>
(string)
The unique identifier of the trained model.
</dd>
<dt>
<span class="term">
<code class="literal">nodes</code>
</span>
</dt>
<dd>
<p>
(array of objects)
The deployment stats for each node that currently has the model allocated.
</p>
<details open>
<summary class="title">Properties of node stats</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">average_inference_time_ms</code>
</span>
</dt>
<dd>
(double)
The average time for each inference call to complete on this node.
The average is calculated over the lifetime of the deployment.
</dd>
<dt>
<span class="term">
<code class="literal">average_inference_time_ms_excluding_cache_hits</code>
</span>
</dt>
<dd>
(double)
The average time to perform inference on the trained model excluding
occasions where the response comes from the cache. Cached inference
calls return very quickly as the model is not evaluated, by excluding
cache hits this value is an accurate measure of the average time taken
to evaluate the model.
</dd>
<dt>
<span class="term">
<code class="literal">average_inference_time_ms_last_minute</code>
</span>
</dt>
<dd>
(double)
The average time for each inference call to complete on this node
in the last minute.
</dd>
<dt>
<span class="term">
<code class="literal">error_count</code>
</span>
</dt>
<dd>
(integer)
The number of errors when evaluating the trained model.
</dd>
<dt>
<span class="term">
<code class="literal">inference_cache_hit_count</code>
</span>
</dt>
<dd>
(integer)
The total number of inference calls made against this node for this
model that were served from the inference cache.
</dd>
<dt>
<span class="term">
<code class="literal">inference_cache_hit_count_last_minute</code>
</span>
</dt>
<dd>
(integer)
The number of inference calls made against this node for this model
in the last minute that were served from the inference cache.
</dd>
<dt>
<span class="term">
<code class="literal">inference_count</code>
</span>
</dt>
<dd>
(integer)
The total number of inference calls made against this node for this model.
</dd>
<dt>
<span class="term">
<code class="literal">last_access</code>
</span>
</dt>
<dd>
(long)
The epoch time stamp of the last inference call for the model on this node.
</dd>
<dt>
<span class="term">
<code class="literal">node</code>
</span>
</dt>
<dd>
<p>
(object)
Information pertaining to the node.
</p>
<details open>
<summary class="title">Properties of node</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">attributes</code>
</span>
</dt>
<dd>
(object)
Lists node attributes such as <code class="literal">ml.machine_memory</code> or <code class="literal">ml.max_open_jobs</code> settings.
</dd>
<dt>
<span class="term">
<code class="literal">ephemeral_id</code>
</span>
</dt>
<dd>
(string)
The ephemeral ID of the node.
</dd>
<dt>
<span class="term">
<code class="literal">id</code>
</span>
</dt>
<dd>
(string)
The unique identifier of the node.
</dd>
<dt>
<span class="term">
<code class="literal">name</code>
</span>
</dt>
<dd>
(string) The node name.
</dd>
<dt>
<span class="term">
<code class="literal">transport_address</code>
</span>
</dt>
<dd>
(string)
The host and port where transport HTTP connections are accepted.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">number_of_allocations</code>
</span>
</dt>
<dd>
(integer)
The number of allocations assigned to this node.
</dd>
<dt>
<span class="term">
<code class="literal">number_of_pending_requests</code>
</span>
</dt>
<dd>
(integer)
The number of inference requests queued to be processed.
</dd>
<dt>
<span class="term">
<code class="literal">peak_throughput_per_minute</code>
</span>
</dt>
<dd>
(integer)
The peak number of requests processed in a 1 minute period.
</dd>
<dt>
<span class="term">
<code class="literal">routing_state</code>
</span>
</dt>
<dd>
<p>
(object)
The current routing state and reason for the current routing state for this allocation.
</p>
<details open>
<summary class="title">Properties of routing_state</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">reason</code>
</span>
</dt>
<dd>
(string)
The reason for the current state. Usually only populated when the <code class="literal">routing_state</code> is <code class="literal">failed</code>.
</dd>
<dt>
<span class="term">
<code class="literal">routing_state</code>
</span>
</dt>
<dd>
(string)
The current routing state.
</dd>
</dl>
</div>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">starting</code>: The model is attempting to allocate on this model, inference calls are not yet accepted.
</li>
<li class="listitem">
<code class="literal">started</code>: The model is allocated and ready to accept inference requests.
</li>
<li class="listitem">
<code class="literal">stopping</code>: The model is being deallocated from this node.
</li>
<li class="listitem">
<code class="literal">stopped</code>: The model is fully deallocated from this node.
</li>
<li class="listitem">
<code class="literal">failed</code>: The allocation attempt failed, see <code class="literal">reason</code> field for the potential cause.
</li>
</ul>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">rejected_execution_count</code>
</span>
</dt>
<dd>
(integer)
The number of inference requests that were not processed because the
queue was full.
</dd>
<dt>
<span class="term">
<code class="literal">start_time</code>
</span>
</dt>
<dd>
(long)
The epoch timestamp when the allocation started.
</dd>
<dt>
<span class="term">
<code class="literal">threads_per_allocation</code>
</span>
</dt>
<dd>
(integer)
The number of threads for each allocation during inference.
This value is limited by the number of hardware threads on the node;
it might therefore differ from the <code class="literal">threads_per_allocation</code> value in the <a class="xref" href="ml-df-trained-models-apis.html#start-trained-model-deployment" title="Start trained model deployment API">Start trained model deployment</a> API.
</dd>
<dt>
<span class="term">
<code class="literal">timeout_count</code>
</span>
</dt>
<dd>
(integer)
The number of inference requests that timed out before being processed.
</dd>
<dt>
<span class="term">
<code class="literal">throughput_last_minute</code>
</span>
</dt>
<dd>
(integer)
The number of requests processed in the last 1 minute.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">number_of_allocations</code>
</span>
</dt>
<dd>
(integer)
The requested number of allocations for the trained model deployment.
</dd>
<dt>
<span class="term">
<code class="literal">peak_throughput_per_minute</code>
</span>
</dt>
<dd>
(integer)
The peak number of requests processed in a 1 minute period for
all nodes in the deployment. This is calculated as the sum of
each node&#8217;s <code class="literal">peak_throughput_per_minute</code> value.
</dd>
<dt>
<span class="term">
<code class="literal">priority</code>
</span>
</dt>
<dd>
(string)
The deployment priority.
</dd>
<dt>
<span class="term">
<code class="literal">rejected_execution_count</code>
</span>
</dt>
<dd>
(integer)
The sum of <code class="literal">rejected_execution_count</code> for all nodes in the deployment.
Individual nodes reject an inference request if the inference queue is full.
The queue size is controlled by the <code class="literal">queue_capacity</code> setting in the
<a class="xref" href="ml-df-trained-models-apis.html#start-trained-model-deployment" title="Start trained model deployment API">Start trained model deployment</a> API.
</dd>
<dt>
<span class="term">
<code class="literal">reason</code>
</span>
</dt>
<dd>
(string)
The reason for the current deployment state.
Usually only populated when the model is not deployed to a node.
</dd>
<dt>
<span class="term">
<code class="literal">start_time</code>
</span>
</dt>
<dd>
(long)
The epoch timestamp when the deployment started.
</dd>
<dt>
<span class="term">
<code class="literal">state</code>
</span>
</dt>
<dd>
<p>
(string)
The overall state of the deployment. The values may be:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">starting</code>: The deployment has recently started but is not yet usable as the model is not allocated on any nodes.
</li>
<li class="listitem">
<code class="literal">started</code>: The deployment is usable as at least one node has the model allocated.
</li>
<li class="listitem">
<code class="literal">stopping</code>: The deployment is preparing to stop and deallocate the model from the relevant nodes.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">threads_per_allocation</code>
</span>
</dt>
<dd>
(integer)
The number of threads per allocation used by the inference process.
</dd>
<dt>
<span class="term">
<code class="literal">timeout_count</code>
</span>
</dt>
<dd>
(integer)
The sum of <code class="literal">timeout_count</code> for all nodes in the deployment.
</dd>
<dt>
<span class="term">
<code class="literal">queue_capacity</code>
</span>
</dt>
<dd>
(integer)
The number of inference requests that may be queued before new requests are
rejected.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">inference_stats</code>
</span>
</dt>
<dd>
<p>
(object)
A collection of inference stats fields.
</p>
<details open>
<summary class="title">Properties of inference stats</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">missing_all_fields_count</code>
</span>
</dt>
<dd>
(integer)
The number of inference calls where all the training features for the model
were missing.
</dd>
<dt>
<span class="term">
<code class="literal">inference_count</code>
</span>
</dt>
<dd>
(integer)
The total number of times the model has been called for inference.
This is across all inference contexts, including all pipelines.
</dd>
<dt>
<span class="term">
<code class="literal">cache_miss_count</code>
</span>
</dt>
<dd>
(integer)
The number of times the model was loaded for inference and was not retrieved
from the cache. If this number is close to the <code class="literal">inference_count</code>, then the cache
is not being appropriately used. This can be solved by increasing the cache size
or its time-to-live (TTL). See <a class="xref" href="settings.html#general-ml-settings" title="General machine learning settings">General machine learning settings</a> for the appropriate
settings.
</dd>
<dt>
<span class="term">
<code class="literal">failure_count</code>
</span>
</dt>
<dd>
(integer)
The number of failures when using the model for inference.
</dd>
<dt>
<span class="term">
<code class="literal">timestamp</code>
</span>
</dt>
<dd>
(<a class="xref" href="api-conventions.html#time-units" title="Time units">time units</a>)
The time when the statistics were last updated.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">ingest</code>
</span>
</dt>
<dd>
(object)
A collection of ingest stats for the model across all nodes. The values are
summations of the individual node statistics. The format matches the <code class="literal">ingest</code>
section in <a class="xref" href="cluster.html#cluster-nodes-stats" title="Nodes stats API">Nodes stats</a>.
</dd>
<dt>
<span class="term">
<code class="literal">model_id</code>
</span>
</dt>
<dd>
(string)
The unique identifier of the trained model.
</dd>
<dt>
<span class="term">
<code class="literal">model_size_stats</code>
</span>
</dt>
<dd>
<p>
(object)
A collection of model size stats fields.
</p>
<details open>
<summary class="title">Properties of model size stats</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">model_size_bytes</code>
</span>
</dt>
<dd>
(integer)
The size of the model in bytes.
</dd>
<dt>
<span class="term">
<code class="literal">required_native_memory_bytes</code>
</span>
</dt>
<dd>
(integer)
The amount of memory required to load the model in bytes.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">pipeline_count</code>
</span>
</dt>
<dd>
(integer)
The number of ingest pipelines that currently refer to the model.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-stats-response-codes"></a>Response codes<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models-stats.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">404</code> (Missing resources)
</span>
</dt>
<dd>
If <code class="literal">allow_no_match</code> is <code class="literal">false</code>, this code indicates that there are no
resources that match the request or only partial matches for the request.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="ml-get-trained-models-stats-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/get-trained-models-stats.asciidoc">edit</a></h3>
</div></div></div>
<p>The following example gets usage information for all the trained models:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">GET _ml/trained_models/_stats</pre>
</div>
<div class="console_widget" data-snippet="snippets/2686.console"></div>
<p>The API returns the following results:</p>
<div class="pre_wrapper lang-console-result">
<pre class="programlisting prettyprint lang-console-result">{
  "count": 2,
  "trained_model_stats": [
    {
      "model_id": "flight-delay-prediction-1574775339910",
      "pipeline_count": 0,
      "inference_stats": {
        "failure_count": 0,
        "inference_count": 4,
        "cache_miss_count": 3,
        "missing_all_fields_count": 0,
        "timestamp": 1592399986979
      }
    },
    {
      "model_id": "regression-job-one-1574775307356",
      "pipeline_count": 1,
      "inference_stats": {
        "failure_count": 0,
        "inference_count": 178,
        "cache_miss_count": 3,
        "missing_all_fields_count": 0,
        "timestamp": 1592399986979
      },
      "ingest": {
        "total": {
          "count": 178,
          "time_in_millis": 8,
          "current": 0,
          "failed": 0
        },
        "pipelines": {
          "flight-delay": {
            "count": 178,
            "time_in_millis": 8,
            "current": 0,
            "failed": 0,
            "processors": [
              {
                "inference": {
                  "type": "inference",
                  "stats": {
                    "count": 178,
                    "time_in_millis": 7,
                    "current": 0,
                    "failed": 0
                  }
                }
              }
            ]
          }
        }
      }
    }
  ]
}</pre>
</div>
</div>

</div>

<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="infer-trained-model"></a>Infer trained model API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/infer-trained-model.asciidoc">edit</a></h2>
</div></div></div>

<p>Evaluates a trained model. The model may be any supervised model either trained
by data frame analytics or imported.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For model deployments with caching enabled, results may be returned
directly from the inference cache.</p>
</div>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="infer-trained-model-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/infer-trained-model.asciidoc">edit</a></h3>
</div></div></div>
<p><code class="literal">POST _ml/trained_models/&lt;model_id&gt;/_infer</code>
<code class="literal">POST _ml/trained_models/&lt;deployment_id&gt;/_infer</code></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="infer-trained-model-path-params"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/infer-trained-model.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;model_id&gt;</code>
</span>
</dt>
<dd>
(Optional, string)
The unique identifier of the trained model or a model alias.
</dd>
</dl>
</div>
<p>If you specify the <code class="literal">model_id</code> in the API call, and the model has multiple
deployments, a random deployment will be used. If the <code class="literal">model_id</code> matches the ID
of one of the deployments, that deployment will be used.</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;deployment_id&gt;</code>
</span>
</dt>
<dd>
(Optional, string)
A unique identifier for the deployment of the model.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="infer-trained-model-query-params"></a>Query parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/infer-trained-model.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">timeout</code>
</span>
</dt>
<dd>
(Optional, time)
Controls the amount of time to wait for inference results. Defaults to 10 seconds.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="infer-trained-model-request-body"></a>Request body<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/infer-trained-model.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">docs</code>
</span>
</dt>
<dd>
(Required, array)
An array of objects to pass to the model for inference. The objects should
contain the fields matching your configured trained model input. Typically for
NLP models, the field name is <code class="literal">text_field</code>.
</dd>
</dl>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">inference_config</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
The default configuration for inference. This can be: <code class="literal">regression</code>,
<code class="literal">classification</code>, <code class="literal">fill_mask</code>, <code class="literal">ner</code>, <code class="literal">question_answering</code>,
<code class="literal">text_classification</code>, <code class="literal">text_embedding</code> or <code class="literal">zero_shot_classification</code>.
If <code class="literal">regression</code> or <code class="literal">classification</code>, it must match the <code class="literal">target_type</code> of the
underlying <code class="literal">definition.trained_model</code>. If <code class="literal">fill_mask</code>, <code class="literal">ner</code>,
<code class="literal">question_answering</code>, <code class="literal">text_classification</code>, or <code class="literal">text_embedding</code>; the
<code class="literal">model_type</code> must be <code class="literal">pytorch</code>. If not specified, the <code class="literal">inference_config</code>
from when the model was created is used.
</p>
<details open>
<summary class="title">Properties of <code class="literal">inference_config</code></summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Classification configuration for inference.
</p>
<details open>
<summary class="title">Properties of classification inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">num_top_classes</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the number of top class predictions to return. Defaults to 0.
</dd>
<dt>
<span class="term">
<code class="literal">num_top_feature_importance_values</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of
<a href="https://www.elastic.co/guide/en/machine-learning/8.9/ml-feature-importance.html" class="ulink" target="_top">feature importance</a> values per document. Defaults
to 0 which means no feature importance calculation occurs.
</dd>
<dt>
<span class="term">
<code class="literal">prediction_field_type</code>
</span>
</dt>
<dd>
(Optional, string)
Specifies the type of the predicted field to write.
Valid values are: <code class="literal">string</code>, <code class="literal">number</code>, <code class="literal">boolean</code>. When <code class="literal">boolean</code> is provided
<code class="literal">1.0</code> is transformed to <code class="literal">true</code> and <code class="literal">0.0</code> to <code class="literal">false</code>.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">top_classes_results_field</code>
</span>
</dt>
<dd>
(Optional, string)
Specifies the field to which the top classes are written. Defaults to
<code class="literal">top_classes</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">fill_mask</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configuration for a fill_mask natural language processing (NLP) task. The
fill_mask task works with models optimized for a fill mask action. For example,
for BERT models, the following text may be provided: "The capital of France is
[MASK].". The response indicates the value most likely to replace <code class="literal">[MASK]</code>. In
this instance, the most probable token is <code class="literal">paris</code>.
</p>
<details open>
<summary class="title">Properties of fill_mask inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">num_top_classes</code>
</span>
</dt>
<dd>
(Optional, integer)
Number of top predicted tokens to return for replacing the mask token. Defaults
to <code class="literal">0</code>.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">ner</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configures a named entity recognition (NER) task. NER is a special case of token
classification. Each token in the sequence is classified according to the
provided classification labels. Currently, the NER task requires the
<code class="literal">classification_labels</code> Inside-Outside-Beginning (IOB) formatted labels. Only
person, organization, location, and miscellaneous are supported.
</p>
<details open>
<summary class="title">Properties of ner inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">pass_through</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configures a <code class="literal">pass_through</code> task. This task is useful for debugging as no
post-processing is done to the inference output and the raw pooling layer
results are returned to the caller.
</p>
<details open>
<summary class="title">Properties of pass_through inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">question_answering</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Configures a question answering natural language processing (NLP) task. Question
answering is useful for extracting answers for certain questions from a large
corpus of text.
</p>
<details open>
<summary class="title">Properties of question_answering inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">max_answer_length</code>
</span>
</dt>
<dd>
(Optional, integer)
The maximum amount of words in the answer. Defaults to <code class="literal">15</code>.
</dd>
<dt>
<span class="term">
<code class="literal">num_top_classes</code>
</span>
</dt>
<dd>
(Optional, integer)
The number the top found answers to return. Defaults to <code class="literal">0</code>, meaning only the
best found answer is returned.
</dd>
<dt>
<span class="term">
<code class="literal">question</code>
</span>
</dt>
<dd>
(Required, string)
The question to use when extracting an answer
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<p>Recommended to set <code class="literal">max_sequence_length</code> to <code class="literal">386</code> with <code class="literal">128</code> of <code class="literal">span</code> and set
<code class="literal">truncate</code> to <code class="literal">none</code>.</p>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">regression</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Regression configuration for inference.
</p>
<details open>
<summary class="title">Properties of regression inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">num_top_feature_importance_values</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the maximum number of
<a href="https://www.elastic.co/guide/en/machine-learning/8.9/ml-feature-importance.html" class="ulink" target="_top">feature importance</a> values per document.
By default, it is zero and no feature importance calculation occurs.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">text_classification</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
A text classification task. Text classification classifies a provided text
sequence into previously known target classes. A specific example of this is
sentiment analysis, which returns the likely target classes indicating text
sentiment, such as "sad", "happy", or "angry".
</p>
<details open>
<summary class="title">Properties of text_classification inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">classification_labels</code>
</span>
</dt>
<dd>
(Optional, string) An array of classification labels.
</dd>
<dt>
<span class="term">
<code class="literal">num_top_classes</code>
</span>
</dt>
<dd>
(Optional, integer)
Specifies the number of top class predictions to return. Defaults to all classes
(-1).
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">text_embedding</code>
</span>
</dt>
<dd>
<p>
(Object, optional)
Text embedding takes an input sequence and transforms it into a vector of
numbers. These embeddings capture not simply tokens, but semantic meanings and
context. These embeddings can be used in a <a class="xref" href="mapping-types.html#dense-vector" title="Dense vector field type">dense vector</a> field
for powerful insights.
</p>
<details open>
<summary class="title">Properties of text_embedding inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">text_similarity</code>
</span>
</dt>
<dd>
<p>
(Object, optional)
Text similarity takes an input sequence and compares it with another input sequence. This is commonly referred to
as cross-encoding. This task is useful for ranking document text when comparing it to another provided text input.
</p>
<details open>
<summary class="title">Properties of text_similarity inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span_score_combination_function</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Identifies how to combine the resulting similarity score when a provided text passage is longer than <code class="literal">max_sequence_length</code> and must be
automatically separated for multiple calls. This only is applicable when <code class="literal">truncate</code> is <code class="literal">none</code> and <code class="literal">span</code> is a non-negative
number. The default value is <code class="literal">max</code>. Available options are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">max</code>: The maximum score from all the spans is returned.
</li>
<li class="listitem">
<code class="literal">mean</code>: The mean score over all the spans is returned.
</li>
</ul>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">text</code>
</span>
</dt>
<dd>
(Required, string)
This is the text with which to compare all document provided text inputs.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
<p>
(Optional, boolean)
Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">[CLS]</code>: The first token of the sequence being classified.
</li>
<li class="listitem">
<code class="literal">[SEP]</code>: Indicates sequence separation.
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">span</code>
</span>
</dt>
<dd>
<p>
(Optional, integer)
When <code class="literal">truncate</code> is <code class="literal">none</code>, you can partition longer text sequences
for inference. The value indicates how many tokens overlap between each
subsequence.
</p>
<p>The default value is <code class="literal">-1</code>, indicating no windowing or spanning occurs.</p>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>When your typical input is just slightly larger than <code class="literal">max_sequence_length</code>, it may be best to simply truncate;
there will be very little information in the second subsequence.</p>
</div>
</div>
</dd>
<dt>
<span class="term">
<code class="literal">with_special_tokens</code>
</span>
</dt>
<dd>
(Optional, boolean)
Tokenize with special tokens if <code class="literal">true</code>.
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">zero_shot_classification</code>
</span>
</dt>
<dd>
<p>
(Object, optional)
Configures a zero-shot classification task. Zero-shot classification allows for
text classification to occur without pre-determined labels. At inference time,
it is possible to adjust the labels to classify. This makes this type of model
and task exceptionally flexible.
</p>
<p>If consistently classifying the same labels, it may be better to use a
fine-tuned text classification model.</p>
<details open>
<summary class="title">Properties of zero_shot_classification inference</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">labels</code>
</span>
</dt>
<dd>
(Optional, array)
The labels to classify. Can be set at creation for default labels, and
then updated during inference.
</dd>
<dt>
<span class="term">
<code class="literal">multi_label</code>
</span>
</dt>
<dd>
(Optional, boolean)
Indicates if more than one <code class="literal">true</code> label is possible given the input.
This is useful when labeling text that could pertain to more than one of the
input labels. Defaults to <code class="literal">false</code>.
</dd>
<dt>
<span class="term">
<code class="literal">results_field</code>
</span>
</dt>
<dd>
(Optional, string)
The field that is added to incoming documents to contain the inference
prediction. Defaults to <code class="literal">predicted_value</code>.
</dd>
<dt>
<span class="term">
<code class="literal">tokenization</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
Indicates the tokenization to perform and the desired settings.
The default tokenization configuration is <code class="literal">bert</code>. Valid tokenization
values are
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">bert</code>: Use for BERT-style models
</li>
<li class="listitem">
<code class="literal">mpnet</code>: Use for MPNet-style models
</li>
<li class="listitem">
<code class="literal">roberta</code>: Use for RoBERTa-style and BART-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">xlm_roberta</code>: Use for XLMRoBERTa-style models
</li>
<li class="listitem">
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> <code class="literal">bert_ja</code>: Use for BERT-style models trained for the Japanese
language.
</li>
</ul>
</div>
<details open>
<summary class="title">Properties of tokenization</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">bert</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
BERT-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
RoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">mpnet</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
MPNet-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of mpnet</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">xlm_roberta</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> XLMRoBERTa-style tokenization is to be performed with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of xlm_roberta</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
<dt>
<span class="term">
<code class="literal">bert_ja</code>
</span>
</dt>
<dd>
<p>
(Optional, object)
<span class="Admonishment Admonishment--preview">
[<span class="Admonishment-title u-mono">preview</span>]
<span class="Admonishment-detail">
This functionality is in technical preview and may be changed or removed in a future release. Elastic will apply best effort to fix any issues, but features in technical preview are not subject to the support SLA of official GA features.
</span>
</span> BERT-style tokenization for Japanese text is to be performed
with the enclosed settings.
</p>
<details open>
<summary class="title">Properties of bert_ja</summary>
<div class="content">
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">truncate</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
Indicates how tokens are truncated when they exceed <code class="literal">max_sequence_length</code>.
The default value is <code class="literal">first</code>.
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">none</code>: No truncation occurs; the inference request receives an error.
</li>
<li class="listitem">
<code class="literal">first</code>: Only the first sequence is truncated.
</li>
<li class="listitem">
<code class="literal">second</code>: Only the second sequence is truncated. If there is just one sequence,
that sequence is truncated.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="note admon">
<div class="icon"></div>
<div class="admon_content">
<p>For <code class="literal">zero_shot_classification</code>, the hypothesis sequence is always the second
sequence. Therefore, do not use <code class="literal">second</code> in this case.</p>
</div>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>
</details>
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="infer-trained-model-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/infer-trained-model.asciidoc">edit</a></h3>
</div></div></div>
<p>The response depends on the kind of model.</p>
<p>For example, for language identification the response is the predicted language and the
score:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ml/trained_models/lang_ident_model_1/_infer
{
  "docs":[{"text": "The fool doth think he is wise, but the wise man knows himself to be a fool."}]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/2687.console"></div>
<p>Here are the results predicting english with a high probability.</p>
<div class="pre_wrapper lang-console-result">
<pre class="programlisting prettyprint lang-console-result">{
  "inference_results": [
    {
      "predicted_value": "en",
      "prediction_probability": 0.9999658805366392,
      "prediction_score": 0.9999658805366392
    }
  ]
}</pre>
</div>
<p>When it is a text classification model, the response is the score and predicted
classification.</p>
<p>For example:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ml/trained_models/model2/_infer
{
	"docs": [{"text_field": "The movie was awesome!!"}]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/2688.console"></div>
<p>The API returns the predicted label and the confidence.</p>
<div class="pre_wrapper lang-console-result">
<pre class="programlisting prettyprint lang-console-result">{
  "inference_results": [{
    "predicted_value" : "POSITIVE",
    "prediction_probability" : 0.9998667964092964
  }]
}</pre>
</div>
<p>For named entity recognition (NER) models, the response contains the annotated
text output and the recognized entities.</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ml/trained_models/model2/_infer
{
	"docs": [{"text_field": "Hi my name is Josh and I live in Berlin"}]
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/2689.console"></div>
<p>The API returns in this case:</p>
<div class="pre_wrapper lang-console-result">
<pre class="programlisting prettyprint lang-console-result">{
  "inference_results": [{
    "predicted_value" : "Hi my name is [Josh](PER&amp;Josh) and I live in [Berlin](LOC&amp;Berlin)",
    "entities" : [
      {
        "entity" : "Josh",
        "class_name" : "PER",
        "class_probability" : 0.9977303419824,
        "start_pos" : 14,
        "end_pos" : 18
      },
      {
        "entity" : "Berlin",
        "class_name" : "LOC",
        "class_probability" : 0.9992474323902818,
        "start_pos" : 33,
        "end_pos" : 39
      }
    ]
  }]
}</pre>
</div>
<p>Zero-shot classification models require extra configuration defining the class
labels. These labels are passed in the zero-shot inference config.</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ml/trained_models/model2/_infer
{
  "docs": [
    {
      "text_field": "This is a very happy person"
    }
  ],
  "inference_config": {
    "zero_shot_classification": {
      "labels": [
        "glad",
        "sad",
        "bad",
        "rad"
      ],
      "multi_label": false
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/2690.console"></div>
<p>The API returns the predicted label and the confidence, as well as the top
classes:</p>
<div class="pre_wrapper lang-console-result">
<pre class="programlisting prettyprint lang-console-result">{
  "inference_results": [{
    "predicted_value" : "glad",
    "top_classes" : [
      {
        "class_name" : "glad",
        "class_probability" : 0.8061155063386439,
        "class_score" : 0.8061155063386439
      },
      {
        "class_name" : "rad",
        "class_probability" : 0.18218006158387956,
        "class_score" : 0.18218006158387956
      },
      {
        "class_name" : "bad",
        "class_probability" : 0.006325615787634201,
        "class_score" : 0.006325615787634201
      },
      {
        "class_name" : "sad",
        "class_probability" : 0.0053788162898424545,
        "class_score" : 0.0053788162898424545
      }
    ],
    "prediction_probability" : 0.8061155063386439
  }]
}</pre>
</div>
<p>Question answering models require extra configuration defining the question to
answer.</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ml/trained_models/model2/_infer
{
  "docs": [
    {
      "text_field": "&lt;long text to extract answer&gt;"
    }
  ],
  "inference_config": {
    "question_answering": {
      "question": "&lt;question to be answered&gt;"
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/2691.console"></div>
<p>The API returns a response similar to the following:</p>
<div class="pre_wrapper lang-console-result">
<pre class="programlisting prettyprint lang-console-result">{
    "predicted_value": &lt;string subsection of the text that is the answer&gt;,
    "start_offset": &lt;character offset in document to start&gt;,
    "end_offset": &lt;character offset end of the answer,
    "prediction_probability": &lt;prediction score&gt;
}</pre>
</div>
<p>Text similarity models require at least two sequences of text to compare. It&#8217;s
possible to provide multiple strings of text to compare to another text
sequence:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ml/trained_models/cross-encoder__ms-marco-tinybert-l-2-v2/_infer
{
  "docs":[{ "text_field": "Berlin has a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers."}, {"text_field": "New York City is famous for the Metropolitan Museum of Art."}],
  "inference_config": {
    "text_similarity": {
      "text": "How many people live in Berlin?"
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/2692.console"></div>
<p>The response contains the prediction for every string that is compared to the
text provided in the <code class="literal">text_similarity</code>.<code class="literal">text</code> field:</p>
<div class="pre_wrapper lang-console-result">
<pre class="programlisting prettyprint lang-console-result">{
  "inference_results": [
    {
      "predicted_value": 7.235751628875732
    },
    {
      "predicted_value": -11.562295913696289
    }
  ]
}</pre>
</div>
<p>The tokenization truncate option can be overridden when calling the API:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ml/trained_models/model2/_infer
{
  "docs": [{"text_field": "The Amazon rainforest covers most of the Amazon basin in South America"}],
  "inference_config": {
    "ner": {
      "tokenization": {
        "bert": {
          "truncate": "first"
        }
      }
    }
  }
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/2693.console"></div>
<p>When the input has been truncated due to the limit imposed by the model&#8217;s
<code class="literal">max_sequence_length</code> the <code class="literal">is_truncated</code> field appears in the response.</p>
<div class="pre_wrapper lang-console-result">
<pre class="programlisting prettyprint lang-console-result">{
  "inference_results": [{
    "predicted_value" : "The [Amazon](LOC&amp;Amazon) rainforest covers most of the [Amazon](LOC&amp;Amazon) basin in [South America](LOC&amp;South+America)",
    "entities" : [
      {
        "entity" : "Amazon",
        "class_name" : "LOC",
        "class_probability" : 0.9505460915724254,
        "start_pos" : 4,
        "end_pos" : 10
      },
      {
        "entity" : "Amazon",
        "class_name" : "LOC",
        "class_probability" : 0.9969992804311777,
        "start_pos" : 41,
        "end_pos" : 47
      }
    ],
    "is_truncated" : true
  }]
}</pre>
</div>
</div>

</div>

<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="start-trained-model-deployment"></a>Start trained model deployment API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></h2>
</div></div></div>

<p>Starts a new trained model deployment.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="start-trained-model-deployment-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<p><code class="literal">POST _ml/trained_models/&lt;model_id&gt;/deployment/_start</code></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="start-trained-model-deployment-prereq"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<p>Requires the <code class="literal">manage_ml</code> cluster privilege. This privilege is included in the
<code class="literal">machine_learning_admin</code> built-in role.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="start-trained-model-deployment-desc"></a>Description<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<p>Currently only <code class="literal">pytorch</code> models are supported for deployment. Once deployed
the model can be used by the <a class="xref" href="processors.html#inference-processor" title="Inference processor">Inference processor</a>
in an ingest pipeline or directly in the <a class="xref" href="ml-df-trained-models-apis.html#infer-trained-model" title="Infer trained model API">Infer trained model</a> API.</p>
<p>A model can be deployed multiple times by using deployment IDs. A deployment ID
must be unique and should not match any other deployment ID or model ID, unless
it is the same as the ID of the model being deployed. If <code class="literal">deployment_id</code> is not
set, it defaults to the <code class="literal">model_id</code>.</p>
<p>Scaling inference performance can be achieved by setting the parameters
<code class="literal">number_of_allocations</code> and <code class="literal">threads_per_allocation</code>.</p>
<p>Increasing <code class="literal">threads_per_allocation</code> means more threads are used when an
inference request is processed on a node. This can improve inference speed for
certain models. It may also result in improvement to throughput.</p>
<p>Increasing <code class="literal">number_of_allocations</code> means more threads are used to process
multiple inference requests in parallel resulting in throughput improvement.
Each model allocation uses a number of threads defined by
<code class="literal">threads_per_allocation</code>.</p>
<p>Model allocations are distributed across machine learning nodes. All allocations assigned to
a node share the same copy of the model in memory. To avoid thread
oversubscription which is detrimental to performance, model allocations are
distributed in such a way that the total number of used threads does not surpass
the node&#8217;s allocated processors.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="start-trained-model-deployment-path-params"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;model_id&gt;</code>
</span>
</dt>
<dd>
(Required, string)
The unique identifier of the trained model.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="start-trained-model-deployment-query-params"></a>Query parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">cache_size</code>
</span>
</dt>
<dd>
(Optional, <a class="xref" href="api-conventions.html#byte-units" title="Byte size units">byte value</a>)
The inference cache size (in memory outside the JVM heap) per node for the
model. The default value is the size of the model as reported by the
<code class="literal">model_size_bytes</code> field in the <a class="xref" href="ml-df-trained-models-apis.html#get-trained-models-stats" title="Get trained models statistics API">Get trained models stats</a>. To disable the
cache, <code class="literal">0b</code> can be provided.
</dd>
<dt>
<span class="term">
<code class="literal">deployment_id</code>
</span>
</dt>
<dd>
(Optional, string)
A unique identifier for the deployment of the model.
</dd>
</dl>
</div>
<p>Defaults to <code class="literal">model_id</code>.</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">number_of_allocations</code>
</span>
</dt>
<dd>
(Optional, integer)
The total number of allocations this model is assigned across machine learning nodes.
Increasing this value generally increases the throughput. Defaults to 1.
</dd>
<dt>
<span class="term">
<code class="literal">priority</code>
</span>
</dt>
<dd>
<p>
(Optional, string)
The priority of the deployment. The default value is <code class="literal">normal</code>.
There are two priority settings:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<code class="literal">normal</code>: Use this for deployments in production. The deployment allocations
are distributed so that node processors are not oversubscribed.
</li>
<li class="listitem">
<code class="literal">low</code>: Use this for testing model functionality. The intention is that these
deployments are not sent a high volume of input. The deployment is required to
have a single allocation with just one thread. Low priority deployments may be
assigned on nodes that already utilize all their processors but will be given a
lower CPU priority than normal deployments. Low priority deployments may be
unassigned in order to satisfy more allocations of normal priority deployments.
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p>Heavy usage of low priority deployments may impact performance of
normal priority deployments.</p>
</div>
</div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">queue_capacity</code>
</span>
</dt>
<dd>
(Optional, integer)
Controls how many inference requests are allowed in the queue at a time.
Every machine learning node in the cluster where the model can be allocated
has a queue of this size; when the number of requests exceeds the total value,
new requests are rejected with a 429 error. Defaults to 1024. Max allowed value
is 1000000.
</dd>
<dt>
<span class="term">
<code class="literal">threads_per_allocation</code>
</span>
</dt>
<dd>
(Optional, integer)
Sets the number of threads used by each model allocation during inference. This
generally increases the speed per inference request. The inference process is a
compute-bound process; <code class="literal">threads_per_allocations</code> must not exceed the number of
available allocated processors per node. Defaults to 1. Must be a power of 2.
Max allowed value is 32.
</dd>
<dt>
<span class="term">
<code class="literal">timeout</code>
</span>
</dt>
<dd>
(Optional, time)
Controls the amount of time to wait for the model to deploy. Defaults to 30
seconds.
</dd>
<dt>
<span class="term">
<code class="literal">wait_for</code>
</span>
</dt>
<dd>
(Optional, string)
Specifies the allocation status to wait for before returning. Defaults to
<code class="literal">started</code>. The value <code class="literal">starting</code> indicates deployment is starting but not yet on
any node. The value <code class="literal">started</code> indicates the model has started on at least one
node. The value <code class="literal">fully_allocated</code> indicates the deployment has started on all
valid nodes.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="start-trained-model-deployment-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<p>The following example starts a new deployment for a
<code class="literal">elastic__distilbert-base-uncased-finetuned-conll03-english</code> trained model:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ml/trained_models/elastic__distilbert-base-uncased-finetuned-conll03-english/deployment/_start?wait_for=started&amp;timeout=1m</pre>
</div>
<div class="console_widget" data-snippet="snippets/2694.console"></div>
<p>The API returns the following results:</p>
<div class="pre_wrapper lang-console-result">
<pre class="programlisting prettyprint lang-console-result">{
    "assignment": {
        "task_parameters": {
            "model_id": "elastic__distilbert-base-uncased-finetuned-conll03-english",
            "model_bytes": 265632637,
            "threads_per_allocation" : 1,
            "number_of_allocations" : 1,
            "queue_capacity" : 1024,
            "priority": "normal"
        },
        "routing_table": {
            "uckeG3R8TLe2MMNBQ6AGrw": {
                "routing_state": "started",
                "reason": ""
            }
        },
        "assignment_state": "started",
        "start_time": "2022-11-02T11:50:34.766591Z"
    }
}</pre>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="start-trained-model-deployment-deployment-id-example"></a>Using deployment IDs<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc">edit</a></h4>
</div></div></div>
<p>The following example starts a new deployment for the <code class="literal">my_model</code> trained model
with the ID <code class="literal">my_model_for_ingest</code>. The deployment ID an be used in inference API
calls or in inference processors.</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ml/trained_models/my_model/deployment/_start?deployment_id=my_model_for_ingest</pre>
</div>
<div class="console_widget" data-snippet="snippets/2695.console"></div>
<p>The <code class="literal">my_model</code> trained model can be deployed again with a different ID:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ml/trained_models/my_model/deployment/_start?deployment_id=my_model_for_search</pre>
</div>
<div class="console_widget" data-snippet="snippets/2696.console"></div>
</div>

</div>

</div>

<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="stop-trained-model-deployment"></a>Stop trained model deployment API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/stop-trained-model-deployment.asciidoc">edit</a></h2>
</div></div></div>

<p>Stops a trained model deployment.</p>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="stop-trained-model-deployment-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/stop-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<p><code class="literal">POST _ml/trained_models/&lt;deployment_id&gt;/deployment/_stop</code></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="stop-trained-model-deployment-prereq"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/stop-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<p>Requires the <code class="literal">manage_ml</code> cluster privilege. This privilege is included in the
<code class="literal">machine_learning_admin</code> built-in role.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="stop-trained-model-deployment-desc"></a>Description<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/stop-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<p>Deployment is required only for trained models that have a PyTorch <code class="literal">model_type</code>.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="stop-trained-model-deployment-path-params"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/stop-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;deployment_id&gt;</code>
</span>
</dt>
<dd>
(Required, string)
A unique identifier for the deployment of the model.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="stop-trained-model-deployment-query-params"></a>Query parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/stop-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">allow_no_match</code>
</span>
</dt>
<dd>
<p>
(Optional, Boolean)
Specifies what to do when the request:
</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Contains wildcard expressions and there are no deployments that match.
</li>
<li class="listitem">
Contains the <code class="literal">_all</code> string or no identifiers and there are no matches.
</li>
<li class="listitem">
Contains wildcard expressions and there are only partial matches.
</li>
</ul>
</div>
<p>The default value is <code class="literal">true</code>, which returns an empty array when there are no
matches and the subset of results when there are partial matches. If this
parameter is <code class="literal">false</code>, the request returns a <code class="literal">404</code> status code when there are no
matches or only partial matches.</p>
</dd>
<dt>
<span class="term">
<code class="literal">force</code>
</span>
</dt>
<dd>
(Optional, Boolean) If true, the deployment is stopped even if it or one of its
model aliases is referenced by ingest pipelines. You can&#8217;t use these pipelines
until you restart the model deployment.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="stop-trained-model-deployment-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/stop-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<p>The following example stops the <code class="literal">my_model_for_search</code> deployment:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ml/trained_models/my_model_for_search/deployment/_stop</pre>
</div>
<div class="console_widget" data-snippet="snippets/2697.console"></div>
</div>

</div>

<div class="section xpack">
<div class="titlepage"><div><div>
<h2 class="title"><a id="update-trained-model-deployment"></a>Update trained model deployment API<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/update-trained-model-deployment.asciidoc">edit</a></h2>
</div></div></div>

<p>Updates certain properties of a trained model deployment.</p>
<div class="warning admon">
<div class="icon"></div>
<div class="admon_content">
<p>This functionality is in beta and is subject to change. The design and code is less mature than official GA features and is being provided as-is with no warranties. Beta features are not subject to the support SLA of official GA features.</p>
</div>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="update-trained-model-deployment-request"></a>Request<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/update-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<p><code class="literal">POST _ml/trained_models/&lt;deployment_id&gt;/deployment/_update</code></p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="update-trained-model-deployments-prereqs"></a>Prerequisites<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/update-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<p>Requires the <code class="literal">manage_ml</code> cluster privilege. This privilege is included in the
<code class="literal">machine_learning_admin</code> built-in role.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="update-trained-model-deployment-desc"></a>Description<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/update-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<p>You can update a trained model deployment whose <code class="literal">assignment_state</code> is <code class="literal">started</code>.
You can either increase or decrease the number of allocations of such a deployment.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="update-trained-model-deployments-path-parms"></a>Path parameters<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/update-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">&lt;deployment_id&gt;</code>
</span>
</dt>
<dd>
(Required, string)
A unique identifier for the deployment of the model.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="update-trained-model-deployment-request-body"></a>Request body<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/update-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<code class="literal">number_of_allocations</code>
</span>
</dt>
<dd>
(Optional, integer)
The total number of allocations this model is assigned across machine learning nodes.
Increasing this value generally increases the throughput.
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="update-trained-model-deployment-example"></a>Examples<a class="edit_me" rel="nofollow" title="Edit this page on GitHub" href="https://github.com/elastic/elasticsearch/edit/8.9/docs/reference/ml/trained-models/apis/update-trained-model-deployment.asciidoc">edit</a></h3>
</div></div></div>
<p>The following example updates the deployment for a
 <code class="literal">elastic__distilbert-base-uncased-finetuned-conll03-english</code> trained model to have 4 allocations:</p>
<div class="pre_wrapper lang-console">
<pre class="programlisting prettyprint lang-console">POST _ml/trained_models/elastic__distilbert-base-uncased-finetuned-conll03-english/deployment/_update
{
  "number_of_allocations": 4
}</pre>
</div>
<div class="console_widget" data-snippet="snippets/2698.console"></div>
<p>The API returns the following results:</p>
<div class="pre_wrapper lang-console-result">
<pre class="programlisting prettyprint lang-console-result">{
    "assignment": {
        "task_parameters": {
            "model_id": "elastic__distilbert-base-uncased-finetuned-conll03-english",
            "model_bytes": 265632637,
            "threads_per_allocation" : 1,
            "number_of_allocations" : 4,
            "queue_capacity" : 1024
        },
        "routing_table": {
            "uckeG3R8TLe2MMNBQ6AGrw": {
                "current_allocations": 1,
                "target_allocations": 4,
                "routing_state": "started",
                "reason": ""
            }
        },
        "assignment_state": "started",
        "start_time": "2022-11-02T11:50:34.766591Z"
    }
}</pre>
</div>
</div>

</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="ml-df-analytics-apis.html">« Machine learning data frame analytics APIs</a>
</span>
<span class="next">
<a href="migration-api.html">Migration APIs »</a>
</span>
</div>
</div>
</body>
</html>
